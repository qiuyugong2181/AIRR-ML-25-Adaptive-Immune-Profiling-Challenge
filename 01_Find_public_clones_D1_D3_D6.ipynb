{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13feaac-4716-43b3-86b2-8ddf243c599d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.105209Z",
     "iopub.status.busy": "2025-12-13T15:30:56.104203Z",
     "iopub.status.idle": "2025-12-13T15:30:56.899494Z",
     "shell.execute_reply": "2025-12-13T15:30:56.898849Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.105182Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import argparse\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Iterator, Tuple, Union, List\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV,\n",
    ")\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2a9b4d-453b-49ab-b457-b29b18fbd221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.901148Z",
     "iopub.status.busy": "2025-12-13T15:30:56.900435Z",
     "iopub.status.idle": "2025-12-13T15:30:56.906814Z",
     "shell.execute_reply": "2025-12-13T15:30:56.906285Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.901105Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "AA_ALPHABET = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "\n",
    "\n",
    "def extract_kmers(seq, k=3, alphabet=AA_ALPHABET):\n",
    "    if not isinstance(seq, str):\n",
    "        return []\n",
    "    seq = seq.strip()\n",
    "    n = len(seq)\n",
    "    if n < k:\n",
    "        return []\n",
    "    out = []\n",
    "    for i in range(n - k + 1):\n",
    "        kmer = seq[i:i + k]\n",
    "        if all(c in alphabet for c in kmer):\n",
    "            out.append(kmer)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d78dde9-0536-4e06-8e20-07f90984133c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.907524Z",
     "iopub.status.busy": "2025-12-13T15:30:56.907346Z",
     "iopub.status.idle": "2025-12-13T15:30:56.912103Z",
     "shell.execute_reply": "2025-12-13T15:30:56.911658Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.907510Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_top_seq_format(top_df, dataset_name, default_prob=-999.0):\n",
    "    df = top_df.copy().reset_index(drop=True)\n",
    "\n",
    "    n = len(df)\n",
    "    df.insert(0, \"ID\", [f\"{dataset_name}_seq_top_{i+1}\" for i in range(n)])\n",
    "    df.insert(1, \"dataset\", dataset_name)\n",
    "    df.insert(2, \"label_positive_probability\", float(default_prob))\n",
    "\n",
    "    cols = [\n",
    "        \"ID\",\n",
    "        \"dataset\",\n",
    "        \"label_positive_probability\",\n",
    "        \"junction_aa\",\n",
    "        \"v_call\",\n",
    "        \"j_call\",\n",
    "    ]\n",
    "    # keep importance_score (and any other extra cols) at the end\n",
    "    cols = cols + [c for c in df.columns if c not in cols]\n",
    "    return df[cols]\n",
    "def to_submission_format(test_pred_df, dataset_name=\"test_dataset_1\"):\n",
    "    df = test_pred_df.copy()\n",
    "\n",
    "    df[\"ID\"] = df[\"repertoire_id\"]\n",
    "    df[\"dataset\"] = dataset_name\n",
    "    df[\"label_positive_probability\"] = df[\"prediction\"]\n",
    "\n",
    "    df[\"junction_aa\"] = -999.0\n",
    "    df[\"v_call\"] = -999.0\n",
    "    df[\"j_call\"] = -999.0\n",
    "\n",
    "    cols = [\n",
    "        \"ID\",\n",
    "        \"dataset\",\n",
    "        \"label_positive_probability\",\n",
    "        \"junction_aa\",\n",
    "        \"v_call\",\n",
    "        \"j_call\",\n",
    "    ]\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ea3e1ae-8718-4865-b03c-b89f64e7ca8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.912761Z",
     "iopub.status.busy": "2025-12-13T15:30:56.912612Z",
     "iopub.status.idle": "2025-12-13T15:30:56.921924Z",
     "shell.execute_reply": "2025-12-13T15:30:56.921471Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.912747Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_generator(data_dir: str, metadata_filename='metadata.csv') -> Iterator[\n",
    "    Union[Tuple[str, pd.DataFrame, bool], Tuple[str, pd.DataFrame]]]:\n",
    "    \"\"\"\n",
    "    A generator to load immune repertoire data.\n",
    "\n",
    "    This function operates in two modes:\n",
    "    1.  If metadata is found, it yields data based on the metadata file.\n",
    "    2.  If metadata is NOT found, it uses glob to find and yield all '.tsv'\n",
    "        files in the directory.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The path to the directory containing the data.\n",
    "\n",
    "    Yields:\n",
    "        An iterator of tuples. The format depends on the mode:\n",
    "        - With metadata: (repertoire_id, pd.DataFrame, label_positive)\n",
    "        - Without metadata: (filename, pd.DataFrame)\n",
    "    \"\"\"\n",
    "    metadata_path = os.path.join(data_dir, metadata_filename)\n",
    "\n",
    "    if os.path.exists(metadata_path):\n",
    "        metadata_df = pd.read_csv(metadata_path)\n",
    "        for row in metadata_df.itertuples(index=False):\n",
    "            file_path = os.path.join(data_dir, row.filename)\n",
    "            try:\n",
    "                repertoire_df = pd.read_csv(file_path, sep='\\t')\n",
    "                yield row.repertoire_id, repertoire_df, row.label_positive\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: File '{row.filename}' listed in metadata not found. Skipping.\")\n",
    "                continue\n",
    "    else:\n",
    "        search_pattern = os.path.join(data_dir, '*.tsv')\n",
    "        tsv_files = glob.glob(search_pattern)\n",
    "        for file_path in sorted(tsv_files):\n",
    "            try:\n",
    "                filename = os.path.basename(file_path)\n",
    "                repertoire_df = pd.read_csv(file_path, sep='\\t')\n",
    "                yield filename, repertoire_df\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not read file '{file_path}'. Error: {e}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "\n",
    "def load_full_dataset(data_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads all TSV files from a directory and concatenates them into a single DataFrame.\n",
    "\n",
    "    This function handles two scenarios:\n",
    "    1. If metadata.csv exists, it loads data based on the metadata and adds\n",
    "       'repertoire_id' and 'label_positive' columns.\n",
    "    2. If metadata.csv does not exist, it loads all .tsv files and adds\n",
    "       a 'filename' column as an identifier.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The path to the data directory.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A single, concatenated DataFrame containing all the data.\n",
    "    \"\"\"\n",
    "    metadata_path = os.path.join(data_dir, 'metadata.csv')\n",
    "    df_list = []\n",
    "    data_loader = load_data_generator(data_dir=data_dir)\n",
    "\n",
    "    if os.path.exists(metadata_path):\n",
    "        metadata_df = pd.read_csv(metadata_path)\n",
    "        total_files = len(metadata_df)\n",
    "        for rep_id, data_df, label in tqdm(data_loader, total=total_files, desc=\"Loading files\"):\n",
    "            data_df['ID'] = rep_id\n",
    "            data_df['label_positive'] = label\n",
    "            df_list.append(data_df)\n",
    "    else:\n",
    "        search_pattern = os.path.join(data_dir, '*.tsv')\n",
    "        total_files = len(glob.glob(search_pattern))\n",
    "        for filename, data_df in tqdm(data_loader, total=total_files, desc=\"Loading files\"):\n",
    "            data_df['ID'] = os.path.basename(filename).replace(\".tsv\", \"\")\n",
    "            df_list.append(data_df)\n",
    "\n",
    "    if not df_list:\n",
    "        print(\"Warning: No data files were loaded.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    full_dataset_df = pd.concat(df_list, ignore_index=True)\n",
    "    return full_dataset_df\n",
    "\n",
    "def mismatched_neighbors(kmer, alphabet=AA_ALPHABET, max_mismatches=1, include_self=True):\n",
    "    k = len(kmer)\n",
    "    if max_mismatches == 0:\n",
    "        return [kmer] if include_self else []\n",
    "    neighbors = set()\n",
    "    if include_self:\n",
    "        neighbors.add(kmer)\n",
    "    for pos in range(k):\n",
    "        for aa in alphabet:\n",
    "            if aa == kmer[pos]:\n",
    "                continue\n",
    "            new_kmer = kmer[:pos] + aa + kmer[pos + 1 :]\n",
    "            neighbors.add(new_kmer)\n",
    "    return list(neighbors)\n",
    "\n",
    "\n",
    "def mismatch_smooth_counts(counts, k=3, alphabet=AA_ALPHABET):\n",
    "    out = Counter()\n",
    "    for kmer, c in counts.items():\n",
    "        if len(kmer) != k:\n",
    "            continue\n",
    "        for nb in mismatched_neighbors(kmer, alphabet=alphabet, max_mismatches=1, include_self=True):\n",
    "            out[nb] += c\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36cac991-08f2-4397-9a2a-2a07b89d66bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.923209Z",
     "iopub.status.busy": "2025-12-13T15:30:56.923056Z",
     "iopub.status.idle": "2025-12-13T15:30:56.933727Z",
     "shell.execute_reply": "2025-12-13T15:30:56.933296Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.923196Z"
    }
   },
   "outputs": [],
   "source": [
    "AA_ALPHABET = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "\n",
    "\n",
    "def extract_gapped_trimers(seq, patterns=((1,0), (0,1),\n",
    "    (2,0), (0,2), (1,1),\n",
    "    (3,0), (0,3), (2,1), (1,2)), alphabet=AA_ALPHABET):\n",
    "    if not isinstance(seq, str):\n",
    "        return []\n",
    "    seq = seq.strip()\n",
    "    n = len(seq)\n",
    "    out = []\n",
    "    for gap1, gap2 in patterns:\n",
    "        window = 3 + gap1 + gap2\n",
    "        if n < window:\n",
    "            continue\n",
    "        for i in range(n - window + 1):\n",
    "            a = seq[i]\n",
    "            b = seq[i + 1 + gap1]\n",
    "            c = seq[i + 2 + gap1 + gap2]\n",
    "            if a in alphabet and b in alphabet and c in alphabet:\n",
    "                key = f\"{a}{b}{c}|g{gap1}{gap2}\"\n",
    "                out.append(key)\n",
    "    return out\n",
    "\n",
    "\n",
    "def encode_repertoire(\n",
    "    seqs,\n",
    "    k=3,\n",
    "    use_gaps=False,\n",
    "    use_mismatch=False,\n",
    "    gap_patterns=((1,0), (0,1),\n",
    "    (2,0), (0,2), (1,1),\n",
    "    (3,0), (0,3), (2,1), (1,2)),\n",
    "    alphabet=AA_ALPHABET,\n",
    "):\n",
    "    exact_counts = Counter()\n",
    "    gap_counts = Counter()\n",
    "\n",
    "    for s in seqs:\n",
    "        if not isinstance(s, str):\n",
    "            continue\n",
    "        exact_counts.update(extract_kmers(s, k=k, alphabet=alphabet))\n",
    "        if use_gaps and k == 3:\n",
    "            gap_counts.update(\n",
    "                extract_gapped_trimers(\n",
    "                    s,\n",
    "                    patterns=gap_patterns,\n",
    "                    alphabet=alphabet,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    if use_mismatch:\n",
    "        mm_counts = mismatch_smooth_counts(exact_counts, k=k, alphabet=alphabet)\n",
    "    else:\n",
    "        mm_counts = Counter()\n",
    "\n",
    "    features = {}\n",
    "    for kmer, c in exact_counts.items():\n",
    "        features[f\"exact_{kmer}\"] = c\n",
    "    for kmer, c in gap_counts.items():\n",
    "        features[f\"gap_{kmer}\"] = c\n",
    "    for kmer, c in mm_counts.items():\n",
    "        features[f\"mm1_{kmer}\"] = c\n",
    "\n",
    "    return features\n",
    "\n",
    "def load_and_encode_repertoires_advanced(\n",
    "    data_dir,\n",
    "    k=3,\n",
    "    use_gaps=False,\n",
    "    use_mismatch=False,\n",
    "    metadata_filename=\"metadata.csv\",\n",
    "    n_jobs=None,\n",
    "):\n",
    "    metadata_path = os.path.join(data_dir, metadata_filename)\n",
    "    use_metadata = os.path.exists(metadata_path)\n",
    "\n",
    "    tasks = []\n",
    "\n",
    "    if use_metadata:\n",
    "        metadata_df = pd.read_csv(metadata_path)\n",
    "        for row in metadata_df.itertuples(index=False):\n",
    "            path = os.path.join(data_dir, row.filename)\n",
    "            tasks.append((row.repertoire_id, path, row.label_positive, k, use_gaps, use_mismatch))\n",
    "    else:\n",
    "        pattern = os.path.join(data_dir, \"*.tsv\")\n",
    "        files = sorted(glob.glob(pattern))\n",
    "        for path in files:\n",
    "            rep_id = os.path.basename(path).replace(\".tsv\", \"\")\n",
    "            tasks.append((rep_id, path, None, k, use_gaps, use_mismatch))\n",
    "\n",
    "    total = len(tasks)\n",
    "    if total == 0:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    if n_jobs is None or n_jobs < 1:\n",
    "        n_jobs = cpu_count()\n",
    "\n",
    "    feature_records = []\n",
    "    meta_records = []\n",
    "\n",
    "    with Pool(processes=n_jobs) as pool:\n",
    "        for feats, meta in tqdm(\n",
    "            pool.imap(_encode_one_repertoire, tasks),\n",
    "            total=total,\n",
    "            desc=f\"Encoding k={k} advanced\",\n",
    "        ):\n",
    "            feature_records.append(feats)\n",
    "            meta_records.append(meta)\n",
    "\n",
    "    X = pd.DataFrame(feature_records).fillna(0).set_index(\"ID\")\n",
    "    meta_df = pd.DataFrame(meta_records)\n",
    "    return X, meta_df\n",
    "\n",
    "def _encode_one_repertoire(args):\n",
    "    rep_id, path, label, k, use_gaps, use_mismatch = args\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "    seqs = df[\"junction_aa\"].dropna().astype(str).tolist()\n",
    "    feats = encode_repertoire(\n",
    "        seqs,\n",
    "        k=k,\n",
    "        use_gaps=use_gaps,\n",
    "        use_mismatch=use_mismatch,\n",
    "    )\n",
    "    feats[\"ID\"] = rep_id\n",
    "\n",
    "    meta = {\"ID\": rep_id}\n",
    "    if label is not None:\n",
    "        meta[\"label_positive\"] = label\n",
    "\n",
    "    return feats, meta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acedfd30-e727-48ba-8016-f107fbcd3ba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.934265Z",
     "iopub.status.busy": "2025-12-13T15:30:56.934127Z",
     "iopub.status.idle": "2025-12-13T15:30:56.938721Z",
     "shell.execute_reply": "2025-12-13T15:30:56.938269Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.934252Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def fit_xgb_no_leakage_with_importance(\n",
    "    X,\n",
    "    y,\n",
    "    n_top_features=200,\n",
    "    random_state=123,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "):\n",
    "    y_arr = np.asarray(y).astype(int)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y_arr,\n",
    "        test_size=0.2,\n",
    "        stratify=y_arr,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    model_full, cv_scores_full, importance_full = fit_xgb(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        random_state=random_state,\n",
    "        n_iter=n_iter,\n",
    "        n_jobs=n_jobs,\n",
    "    )\n",
    "\n",
    "    top_features = importance_full[\"feature\"].head(n_top_features).tolist()\n",
    "\n",
    "    X_train_top = X_train.loc[:, top_features]\n",
    "    X_test_top = X_test.loc[:, top_features]\n",
    "\n",
    "    model_top, cv_scores_top, importance_top = fit_xgb(\n",
    "        X_train_top,\n",
    "        y_train,\n",
    "        random_state=random_state,\n",
    "        n_iter=n_iter,\n",
    "        n_jobs=n_jobs,\n",
    "    )\n",
    "\n",
    "    y_test_pred = model_top.predict_proba(X_test_top)[:, 1]\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\n",
    "        \"initial_model\": model_full,\n",
    "        \"initial_cv_scores\": cv_scores_full,\n",
    "        \"initial_importance\": importance_full,\n",
    "        \"selected_features\": top_features,\n",
    "        \"final_model\": model_top,\n",
    "        \"final_cv_scores\": cv_scores_top,\n",
    "        \"final_importance\": importance_top,\n",
    "        \"test_auc\": test_auc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004431ec-4365-44c8-8842-65b6f89f0800",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.939313Z",
     "iopub.status.busy": "2025-12-13T15:30:56.939174Z",
     "iopub.status.idle": "2025-12-13T15:30:56.946195Z",
     "shell.execute_reply": "2025-12-13T15:30:56.945786Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.939300Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_xgb(X, y, random_state=123, n_iter=150, n_jobs=-1):\n",
    "    y_arr = np.asarray(y).astype(int)\n",
    "\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    max_depth_values = np.arange(3, 8)\n",
    "    n_estimators_values = np.linspace(200, 1000, 9, dtype=int)\n",
    "    learning_rate_values = np.logspace(-3, -0.7, 8)\n",
    "    subsample_values = np.linspace(0.6, 1.0, 5)\n",
    "    colsample_bytree_values = np.linspace(0.6, 1.0, 5)\n",
    "    min_child_weight_values = [3, 5, 7]\n",
    "    gamma_values = [0.0, 0.1, 0.2, 0.5]\n",
    "    reg_lambda_values = np.logspace(-1, 2, 6)\n",
    "    reg_alpha_values = [0.0, 1e-3, 1e-2, 1e-1, 1.0, 10.0]\n",
    "\n",
    "    fixed_params = dict(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "        device=\"cpu\",\n",
    "    )\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"max_depth\": trial.suggest_categorical(\"max_depth\", list(max_depth_values)),\n",
    "            \"n_estimators\": trial.suggest_categorical(\"n_estimators\", list(n_estimators_values)),\n",
    "            \"learning_rate\": trial.suggest_categorical(\"learning_rate\", list(learning_rate_values)),\n",
    "            \"subsample\": trial.suggest_categorical(\"subsample\", list(subsample_values)),\n",
    "            \"colsample_bytree\": trial.suggest_categorical(\"colsample_bytree\", list(colsample_bytree_values)),\n",
    "            \"min_child_weight\": trial.suggest_categorical(\"min_child_weight\", min_child_weight_values),\n",
    "            \"gamma\": trial.suggest_categorical(\"gamma\", gamma_values),\n",
    "            \"reg_lambda\": trial.suggest_categorical(\"reg_lambda\", list(reg_lambda_values)),\n",
    "            \"reg_alpha\": trial.suggest_categorical(\"reg_alpha\", reg_alpha_values),\n",
    "        }\n",
    "        model = XGBClassifier(**fixed_params, **params)\n",
    "        scores = cross_val_score(\n",
    "            model,\n",
    "            X.values,\n",
    "            y_arr,\n",
    "            cv=cv,\n",
    "            scoring=\"roc_auc\",\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=random_state)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=n_iter, n_jobs=7,    show_progress_bar=True)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_model = XGBClassifier(**fixed_params, **best_params)\n",
    "    best_model.fit(X.values, y_arr)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        best_model,\n",
    "        X.values,\n",
    "        y_arr,\n",
    "        cv=cv,\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=n_jobs,\n",
    "    )\n",
    "\n",
    "    importance = pd.DataFrame(\n",
    "        {\"feature\": X.columns, \"importance\": best_model.feature_importances_}\n",
    "    ).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    return best_model, scores, importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6694980a-04e4-4c83-adcb-4027ab7c31f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.946816Z",
     "iopub.status.busy": "2025-12-13T15:30:56.946667Z",
     "iopub.status.idle": "2025-12-13T15:30:56.950776Z",
     "shell.execute_reply": "2025-12-13T15:30:56.950305Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.946802Z"
    }
   },
   "outputs": [],
   "source": [
    "def basic_kmer_feature_filter(X, min_nonzero_repertoires=5, min_total_count=10):\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        X = pd.DataFrame(X)\n",
    "\n",
    "    nonzero_counts = (X != 0).sum(axis=0)\n",
    "    total_counts = X.sum(axis=0)\n",
    "\n",
    "    mask = (nonzero_counts >= min_nonzero_repertoires) & (total_counts >= min_total_count)\n",
    "    X_filtered = X.loc[:, mask]\n",
    "    selected_features = X_filtered.columns.tolist()\n",
    "    return X_filtered, selected_features\n",
    "\n",
    "\n",
    "def apply_feature_filter(X, selected_features):\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        X = pd.DataFrame(X)\n",
    "\n",
    "    for f in selected_features:\n",
    "        if f not in X.columns:\n",
    "            X[f] = 0\n",
    "\n",
    "    return X[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "993c1670-6ff8-4831-a187-2d66102d1df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.951575Z",
     "iopub.status.busy": "2025-12-13T15:30:56.951425Z",
     "iopub.status.idle": "2025-12-13T15:30:56.955339Z",
     "shell.execute_reply": "2025-12-13T15:30:56.954918Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.951562Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_kmer_rows_by_category(X, col_categories=None):\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        X = pd.DataFrame(X)\n",
    "\n",
    "    if col_categories is None:\n",
    "        cats = []\n",
    "        for c in X.columns:\n",
    "            if \"_\" in c:\n",
    "                prefix = c.split(\"_\", 1)[0]\n",
    "                if prefix == \"gap\" and \"|g\" in c:\n",
    "                    code = c.split(\"|g\", 1)[1]\n",
    "                    cat = f\"gap_g{code}\"\n",
    "                else:\n",
    "                    cat = prefix\n",
    "            else:\n",
    "                cat = \"other\"\n",
    "            cats.append(cat)\n",
    "        col_categories = pd.Index(cats)\n",
    "    else:\n",
    "        col_categories = pd.Index(col_categories)\n",
    "\n",
    "    group_sums = X.groupby(col_categories, axis=1).transform(\"sum\")\n",
    "    X_norm = X.div(group_sums.replace(0, np.nan))\n",
    "    return X_norm.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9bf8c0a-c873-4999-8777-c25faa923ee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.955973Z",
     "iopub.status.busy": "2025-12-13T15:30:56.955829Z",
     "iopub.status.idle": "2025-12-13T15:30:56.966911Z",
     "shell.execute_reply": "2025-12-13T15:30:56.966439Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.955960Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _score_one_sequence(\n",
    "    s,\n",
    "    k,\n",
    "    alphabet,\n",
    "    gap_patterns,\n",
    "    use_gaps,\n",
    "    use_mismatch,\n",
    "    importance_map,\n",
    "):\n",
    "    s = str(s).strip()\n",
    "    if len(s) < k:\n",
    "        return 0.0\n",
    "\n",
    "    exact_kmers = extract_kmers(s, k=k, alphabet=alphabet)\n",
    "    exact_counts = Counter(exact_kmers)\n",
    "\n",
    "    score = 0.0\n",
    "    for kmer, cnt in exact_counts.items():\n",
    "        feat_name = f\"exact_{kmer}\"\n",
    "        imp = importance_map.get(feat_name)\n",
    "        if imp is not None:\n",
    "            score += imp * cnt\n",
    "\n",
    "    if use_gaps and k == 3:\n",
    "        gapped = extract_gapped_trimers(s, patterns=gap_patterns, alphabet=alphabet)\n",
    "        gap_counts = Counter(gapped)\n",
    "        for gk, cnt in gap_counts.items():\n",
    "            feat_name = f\"gap_{gk}\"\n",
    "            imp = importance_map.get(feat_name)\n",
    "            if imp is not None:\n",
    "                score += imp * cnt\n",
    "\n",
    "    if use_mismatch:\n",
    "        mm_counts = mismatch_smooth_counts(exact_counts, k=k, alphabet=alphabet)\n",
    "        for mk, cnt in mm_counts.items():\n",
    "            feat_name = f\"mm1_{mk}\"\n",
    "            imp = importance_map.get(feat_name)\n",
    "            if imp is not None:\n",
    "                score += imp * cnt\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def score_sequences_by_kmer_importance(\n",
    "    sequences_df: pd.DataFrame,\n",
    "    importance_df: pd.DataFrame,\n",
    "    sequence_col: str = \"junction_aa\",\n",
    "    alphabet=AA_ALPHABET,\n",
    "    gap_patterns=(\n",
    "        (1, 0),\n",
    "        (0, 1),\n",
    "        (2, 0),\n",
    "        (0, 2),\n",
    "        (1, 1),\n",
    "        (3, 0),\n",
    "        (0, 3),\n",
    "        (2, 1),\n",
    "        (1, 2),\n",
    "    ),\n",
    "    use_gaps: bool = True,\n",
    "    use_mismatch: bool = True,\n",
    "    n_jobs: int = None,\n",
    ") -> pd.DataFrame:\n",
    "    if sequence_col not in sequences_df.columns:\n",
    "        raise KeyError(sequence_col)\n",
    "\n",
    "    feat_names = importance_df[\"feature\"].astype(str).tolist()\n",
    "\n",
    "    exact_feats = [f for f in feat_names if f.startswith(\"exact_\")]\n",
    "    k_values = set()\n",
    "\n",
    "    if exact_feats:\n",
    "        k_values = {len(f.split(\"exact_\", 1)[1]) for f in exact_feats}\n",
    "    else:\n",
    "        mm_feats = [f for f in feat_names if f.startswith(\"mm1_\")]\n",
    "        if mm_feats:\n",
    "            k_values = {len(f.split(\"mm1_\", 1)[1]) for f in mm_feats}\n",
    "        else:\n",
    "            gap_feats = [f for f in feat_names if f.startswith(\"gap_\")]\n",
    "            if gap_feats:\n",
    "                tmp = set()\n",
    "                for f in gap_feats:\n",
    "                    rest = f.split(\"gap_\", 1)[1]\n",
    "                    core = rest.split(\"|g\", 1)[0]\n",
    "                    tmp.add(len(core))\n",
    "                k_values = tmp\n",
    "\n",
    "    if not k_values:\n",
    "        raise ValueError(\"Cannot infer k from feature names; expected 'exact_', 'mm1_', or 'gap_' features\")\n",
    "\n",
    "    if len(k_values) != 1:\n",
    "        raise ValueError(\"Inconsistent k across features\")\n",
    "\n",
    "    k = k_values.pop()\n",
    "\n",
    "    importance_map = dict(zip(importance_df[\"feature\"], importance_df[\"importance\"]))\n",
    "\n",
    "    if use_gaps:\n",
    "        has_gap_feats = any(f.startswith(\"gap_\") for f in feat_names)\n",
    "        use_gaps = has_gap_feats and (k == 3)\n",
    "\n",
    "    if use_mismatch:\n",
    "        has_mm_feats = any(f.startswith(\"mm1_\") for f in feat_names)\n",
    "        use_mismatch = has_mm_feats\n",
    "\n",
    "    seq_series = sequences_df[sequence_col].fillna(\"\").astype(str)\n",
    "    n = len(seq_series)\n",
    "\n",
    "    if n_jobs is None or n_jobs < 1:\n",
    "        n_jobs = cpu_count()\n",
    "    else:\n",
    "        n_jobs = min(n_jobs, cpu_count())\n",
    "\n",
    "    if n_jobs == 1:\n",
    "        scores = [\n",
    "            _score_one_sequence(\n",
    "                s,\n",
    "                k,\n",
    "                alphabet,\n",
    "                gap_patterns,\n",
    "                use_gaps,\n",
    "                use_mismatch,\n",
    "                importance_map,\n",
    "            )\n",
    "            for s in tqdm(seq_series, desc=\"scoring sequences\", total=n)\n",
    "        ]\n",
    "    else:\n",
    "        worker = partial(\n",
    "            _score_one_sequence,\n",
    "            k=k,\n",
    "            alphabet=alphabet,\n",
    "            gap_patterns=gap_patterns,\n",
    "            use_gaps=use_gaps,\n",
    "            use_mismatch=use_mismatch,\n",
    "            importance_map=importance_map,\n",
    "        )\n",
    "        chunksize = max(1, n // (n_jobs * 8))\n",
    "\n",
    "        with Pool(processes=n_jobs) as pool:\n",
    "            scores = list(\n",
    "                tqdm(\n",
    "                    pool.imap(worker, seq_series, chunksize=chunksize),\n",
    "                    total=n,\n",
    "                    desc=\"scoring sequences\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "    out = sequences_df.copy()\n",
    "    out[\"importance_score\"] = scores\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85c6a838-4b76-4060-a9c6-08996ae925c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.967563Z",
     "iopub.status.busy": "2025-12-13T15:30:56.967384Z",
     "iopub.status.idle": "2025-12-13T15:30:56.971290Z",
     "shell.execute_reply": "2025-12-13T15:30:56.970928Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.967550Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset_pairs(train_dir: str, test_dir: str) -> List[Tuple[str, List[str]]]:\n",
    "    \"\"\"Returns list of (train_path, [test_paths]) tuples for dataset pairs.\"\"\"\n",
    "    test_groups = defaultdict(list)\n",
    "    for test_name in sorted(os.listdir(test_dir)):\n",
    "        if test_name.startswith(\"test_dataset_\"):\n",
    "            base_id = test_name.replace(\"test_dataset_\", \"\").split(\"_\")[0]\n",
    "            test_groups[base_id].append(os.path.join(test_dir, test_name))\n",
    "\n",
    "    pairs = []\n",
    "    for train_name in sorted(os.listdir(train_dir)):\n",
    "        if train_name.startswith(\"train_dataset_\"):\n",
    "            train_id = train_name.replace(\"train_dataset_\", \"\")\n",
    "            train_path = os.path.join(train_dir, train_name)\n",
    "            pairs.append((train_path, test_groups.get(train_id, [])))\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "179dbcce-85b0-40e8-8b59-a5c014ef9b21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.971974Z",
     "iopub.status.busy": "2025-12-13T15:30:56.971829Z",
     "iopub.status.idle": "2025-12-13T15:30:56.977235Z",
     "shell.execute_reply": "2025-12-13T15:30:56.976765Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.971962Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def load_and_encode_vj(folder_path: str, feature_colums=('v_call', 'j_call')):\n",
    "    base_dir = Path(folder_path)\n",
    "    dataset_name = base_dir.name\n",
    "\n",
    "    dir_entries = list(base_dir.iterdir())\n",
    "    tsv_list = [entry for entry in dir_entries if entry.suffix == '.tsv']\n",
    "    non_tsv_names = [entry.name for entry in dir_entries if entry.suffix != '.tsv']\n",
    "    print(f'Loading {len(tsv_list)} .tsv files from {dataset_name} (remaining: {non_tsv_names}).')\n",
    "\n",
    "    meta_df = None\n",
    "    meta_file = base_dir / 'metadata.csv'\n",
    "    if meta_file.exists():\n",
    "        meta_df = pd.read_csv(meta_file)\n",
    "        meta_df.set_index('filename', inplace=True)\n",
    "\n",
    "    records = []\n",
    "    for tsv_file in tqdm(tsv_list, desc='Loading TSV files'):\n",
    "        try:\n",
    "            tab = pd.read_csv(tsv_file, sep='\\t')\n",
    "        except Exception as exc:\n",
    "            print(f\"Error loading {tsv_file.name}: {exc}\")\n",
    "            continue\n",
    "\n",
    "        row_dict = {\n",
    "            'ID': tsv_file.stem,\n",
    "            'dataset': dataset_name,\n",
    "        }\n",
    "\n",
    "        if meta_df is not None and tsv_file.name in meta_df.index:\n",
    "            row_dict['label_positive'] = int(meta_df.at[tsv_file.name, 'label_positive'])\n",
    "\n",
    "        total_rows = len(tab)\n",
    "        for feature in feature_colums:\n",
    "            if feature not in tab.columns or total_rows == 0:\n",
    "                continue\n",
    "            freq_series = tab[feature].value_counts() / total_rows\n",
    "            row_dict.update(freq_series.to_dict())\n",
    "\n",
    "        records.append(row_dict)\n",
    "\n",
    "    return pd.DataFrame(records).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90a936bf-7ff1-4ef6-97d2-1a9deb9d3744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.977895Z",
     "iopub.status.busy": "2025-12-13T15:30:56.977751Z",
     "iopub.status.idle": "2025-12-13T15:30:56.983583Z",
     "shell.execute_reply": "2025-12-13T15:30:56.983212Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.977883Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def split_kmer_and_gap_families(X_train_norm, X_test_norm):\n",
    "    def _subset(df, cols):\n",
    "        if not cols:\n",
    "            return pd.DataFrame(index=df.index)\n",
    "        cols_existing = [c for c in cols if c in df.columns]\n",
    "        if not cols_existing:\n",
    "            return pd.DataFrame(index=df.index)\n",
    "        return df.loc[:, cols_existing]\n",
    "\n",
    "    # exact_* features\n",
    "    exact_cols = [c for c in X_train_norm.columns if c.startswith(\"exact_\")]\n",
    "    X_train_exact = _subset(X_train_norm, exact_cols)\n",
    "    X_test_exact = _subset(X_test_norm, exact_cols)\n",
    "\n",
    "    # mm1_* features\n",
    "    mm1_cols = [c for c in X_train_norm.columns if c.startswith(\"mm1_\")]\n",
    "    X_train_mm1 = _subset(X_train_norm, mm1_cols)\n",
    "    X_test_mm1 = _subset(X_test_norm, mm1_cols)\n",
    "\n",
    "    # gap_* features (all)\n",
    "    all_gap_cols = sorted([c for c in X_train_norm.columns if c.startswith(\"gap_\")])\n",
    "    X_train_gap_all = _subset(X_train_norm, all_gap_cols)\n",
    "    X_test_gap_all = _subset(X_test_norm, all_gap_cols)\n",
    "\n",
    "    # split gap_* by pattern code, e.g. 'gap_AAA|g10' -> '10'\n",
    "    def _get_gap_pattern(col):\n",
    "        if not col.startswith(\"gap_\"):\n",
    "            return None\n",
    "        rest = col.split(\"gap_\", 1)[1]\n",
    "        if \"|g\" not in rest:\n",
    "            return None\n",
    "        code = rest.split(\"|g\", 1)[1]\n",
    "        return code\n",
    "\n",
    "    pattern_to_cols = defaultdict(list)\n",
    "    for c in all_gap_cols:\n",
    "        code = _get_gap_pattern(c) or \"unknown\"\n",
    "        pattern_to_cols[code].append(c)\n",
    "\n",
    "    X_train_gap_by_pattern = {}\n",
    "    X_test_gap_by_pattern = {}\n",
    "    for code, cols in pattern_to_cols.items():\n",
    "        X_train_gap_by_pattern[code] = _subset(X_train_norm, cols)\n",
    "        X_test_gap_by_pattern[code] = _subset(X_test_norm, cols)\n",
    "\n",
    "    return {\n",
    "        \"exact\": (X_train_exact, X_test_exact),\n",
    "        \"mm1\": (X_train_mm1, X_test_mm1),\n",
    "        \"gap_all\": (X_train_gap_all, X_test_gap_all),\n",
    "        \"gap_by_pattern\": (X_train_gap_by_pattern, X_test_gap_by_pattern),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "211aeb21-a6a0-42c6-9898-b27a66b332d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.985272Z",
     "iopub.status.busy": "2025-12-13T15:30:56.985123Z",
     "iopub.status.idle": "2025-12-13T15:30:56.990558Z",
     "shell.execute_reply": "2025-12-13T15:30:56.990105Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.985258Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_train_feature_blocks(X_train_norm, vj_train):\n",
    "    parts = split_kmer_and_gap_families(X_train_norm, X_train_norm)\n",
    "\n",
    "    X_train_exact, _ = parts[\"exact\"]\n",
    "    X_train_mm1, _   = parts[\"mm1\"]\n",
    "\n",
    "    gap_train_dict, _ = parts[\"gap_by_pattern\"]\n",
    "\n",
    "    X_train_vj = vj_train.reindex(X_train_norm.index).fillna(0.0)\n",
    "\n",
    "    feature_blocks = {\n",
    "        \"exact\": X_train_exact,\n",
    "        \"mm1\":   X_train_mm1,\n",
    "        \"vj\":    X_train_vj,\n",
    "    }\n",
    "\n",
    "    return feature_blocks, gap_train_dict\n",
    "\n",
    "def train_base_models_for_current_dataset(\n",
    "    X_train_norm,\n",
    "    vj_train,\n",
    "    y_train,\n",
    "    random_state=123,\n",
    "    n_iter=5,\n",
    "    n_jobs=-1,\n",
    "):\n",
    "    feature_blocks, gap_train_dict = build_train_feature_blocks(X_train_norm, vj_train)\n",
    "    print(\"splitting done\")\n",
    "    results = {}\n",
    "\n",
    "    # exact, mm1, vj\n",
    "    print(\"fitting exact, mm1, vj\")\n",
    "\n",
    "    for name, X_block in feature_blocks.items():\n",
    "        if X_block is None or X_block.shape[1] == 0:\n",
    "            continue\n",
    "        model, scores, importance = fit_xgb(\n",
    "            X=X_block,\n",
    "            y=y_train,\n",
    "            random_state=random_state,\n",
    "            n_iter=n_iter,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "        results[name] = {\n",
    "            \"model\": model,\n",
    "            \"cv_scores\": scores,\n",
    "            \"importance\": importance,\n",
    "        }\n",
    "\n",
    "    # individual gap families\n",
    "    print(\"fitting individual gap families\")\n",
    "    for code, X_block in gap_train_dict.items():\n",
    "        if X_block is None or X_block.shape[1] == 0:\n",
    "            continue\n",
    "        model, scores, importance = fit_xgb(\n",
    "            X=X_block,\n",
    "            y=y_train,\n",
    "            random_state=random_state,\n",
    "            n_iter=n_iter,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "        results[f\"gap_g{code}\"] = {\n",
    "            \"model\": model,\n",
    "            \"cv_scores\": scores,\n",
    "            \"importance\": importance,\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37b0c5e4-0697-4f86-9b36-1fc1f8483f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.991037Z",
     "iopub.status.busy": "2025-12-13T15:30:56.990903Z",
     "iopub.status.idle": "2025-12-13T15:30:56.997543Z",
     "shell.execute_reply": "2025-12-13T15:30:56.997071Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.991025Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_base_model_train_probs(X_train_norm, vj_train, base_results):\n",
    "    feature_blocks, gap_train_dict = build_train_feature_blocks(X_train_norm, vj_train)\n",
    "\n",
    "    blocks = {}\n",
    "    for name, X_block in feature_blocks.items():\n",
    "        if X_block is not None and X_block.shape[1] > 0 and name in base_results:\n",
    "            blocks[name] = X_block\n",
    "\n",
    "    for code, X_block in gap_train_dict.items():\n",
    "        key = f\"gap_g{code}\"\n",
    "        if X_block is not None and X_block.shape[1] > 0 and key in base_results:\n",
    "            blocks[key] = X_block\n",
    "\n",
    "    meta_X = pd.DataFrame(index=X_train_norm.index)\n",
    "\n",
    "    for name, X_block in blocks.items():\n",
    "        model = base_results[name][\"model\"]\n",
    "        preds = model.predict_proba(X_block)[:, 1]\n",
    "        meta_X[name] = preds\n",
    "\n",
    "    return meta_X\n",
    "\n",
    "def train_meta_model(meta_X_train, y_train, C=1.0):\n",
    "    lr = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        C=C,\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000)\n",
    "\n",
    "    lr.fit(meta_X_train.values, np.asarray(y_train).astype(int))\n",
    "    return lr\n",
    "\n",
    "def get_base_model_test_probs(X_train_norm, X_test_norm, vj_train, vj_test, base_results):\n",
    "    parts = split_kmer_and_gap_families(X_train_norm, X_test_norm)\n",
    "\n",
    "    _, X_test_exact = parts[\"exact\"]\n",
    "    _, X_test_mm1   = parts[\"mm1\"]\n",
    "    _, gap_test_dict = parts[\"gap_by_pattern\"]\n",
    "\n",
    "    X_test_vj = vj_test.reindex(X_test_norm.index).fillna(0.0)\n",
    "\n",
    "    meta_X_test = pd.DataFrame(index=X_test_norm.index)\n",
    "\n",
    "    for name, info in base_results.items():\n",
    "        model = info[\"model\"]\n",
    "\n",
    "        if name == \"exact\":\n",
    "            X_block = X_test_exact\n",
    "        elif name == \"mm1\":\n",
    "            X_block = X_test_mm1\n",
    "        elif name == \"vj\":\n",
    "            X_block = X_test_vj\n",
    "        elif name.startswith(\"gap_g\"):\n",
    "            code = name[len(\"gap_g\"):]\n",
    "            X_block = gap_test_dict.get(code)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if X_block is None or X_block.shape[1] == 0:\n",
    "            continue\n",
    "\n",
    "        preds = model.predict_proba(X_block)[:, 1]\n",
    "        meta_X_test[name] = preds\n",
    "\n",
    "    return meta_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7066cb2c-965f-4e3e-a113-923d26ffef17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:56.998166Z",
     "iopub.status.busy": "2025-12-13T15:30:56.998021Z",
     "iopub.status.idle": "2025-12-13T15:30:57.004930Z",
     "shell.execute_reply": "2025-12-13T15:30:57.004476Z",
     "shell.execute_reply.started": "2025-12-13T15:30:56.998153Z"
    }
   },
   "outputs": [],
   "source": [
    "def _parse_gap_code(code: str):\n",
    "    if not code.isdigit() or len(code) != 2:\n",
    "        raise ValueError(f\"bad gap code: {code}\")\n",
    "    return (int(code[0]), int(code[1]))\n",
    "\n",
    "\n",
    "def compute_ensemble_sequence_scores(\n",
    "    sequences_df: pd.DataFrame,\n",
    "    base_results: dict,\n",
    "    meta_model,\n",
    "    meta_feature_names,\n",
    "    alphabet=AA_ALPHABET,\n",
    "    n_jobs: int = 1,\n",
    ") -> pd.DataFrame:\n",
    "    coef = meta_model.coef_[0]\n",
    "    name_to_weight = {\n",
    "        name: coef[i]\n",
    "        for i, name in enumerate(meta_feature_names)\n",
    "        if name in base_results\n",
    "    }\n",
    "\n",
    "    seq_scores = sequences_df.copy()\n",
    "    per_model_cols = []\n",
    "\n",
    "    for name, weight in name_to_weight.items():\n",
    "        if abs(weight) < 1e-12:\n",
    "            continue\n",
    "\n",
    "        info = base_results[name]\n",
    "        imp_df = info[\"importance\"]\n",
    "\n",
    "        if name == \"exact\":\n",
    "            scored = score_sequences_by_kmer_importance(\n",
    "                sequences_df,\n",
    "                imp_df,\n",
    "                sequence_col=\"junction_aa\",\n",
    "                alphabet=alphabet,\n",
    "                use_gaps=False,\n",
    "                use_mismatch=False,\n",
    "                n_jobs=n_jobs,\n",
    "            )\n",
    "        elif name == \"mm1\":\n",
    "            scored = score_sequences_by_kmer_importance(\n",
    "                sequences_df,\n",
    "                imp_df,\n",
    "                sequence_col=\"junction_aa\",\n",
    "                alphabet=alphabet,\n",
    "                use_gaps=False,\n",
    "                use_mismatch=True,\n",
    "                n_jobs=n_jobs,\n",
    "            )\n",
    "        elif name.startswith(\"gap_g\"):\n",
    "            code = name[len(\"gap_g\"):]\n",
    "            pattern = _parse_gap_code(code)\n",
    "            scored = score_sequences_by_kmer_importance(\n",
    "                sequences_df,\n",
    "                imp_df,\n",
    "                sequence_col=\"junction_aa\",\n",
    "                alphabet=alphabet,\n",
    "                gap_patterns=(pattern,),\n",
    "                use_gaps=True,\n",
    "                use_mismatch=False,\n",
    "                n_jobs=n_jobs,\n",
    "            )\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        col_name = f\"score_{name}\"\n",
    "        seq_scores[col_name] = scored[\"importance_score\"].values * weight\n",
    "        per_model_cols.append(col_name)\n",
    "\n",
    "    if per_model_cols:\n",
    "        seq_scores[\"ensemble_score\"] = seq_scores[per_model_cols].sum(axis=1)\n",
    "    else:\n",
    "        seq_scores[\"ensemble_score\"] = 0.0\n",
    "\n",
    "    return seq_scores\n",
    "def get_top_sequences_ensemble(\n",
    "    unique_seqs: pd.DataFrame,\n",
    "    base_results: dict,\n",
    "    meta_model,\n",
    "    meta_feature_names,\n",
    "    alphabet=AA_ALPHABET,\n",
    "    n_jobs: int = 1,\n",
    "    top_n: int = 50000,\n",
    ") -> pd.DataFrame:\n",
    "    scored = compute_ensemble_sequence_scores(\n",
    "        sequences_df=unique_seqs,\n",
    "        base_results=base_results,\n",
    "        meta_model=meta_model,\n",
    "        meta_feature_names=meta_feature_names,\n",
    "        alphabet=alphabet,\n",
    "        n_jobs=n_jobs,\n",
    "    )\n",
    "    scored_sorted = scored.sort_values(\"ensemble_score\", ascending=False)\n",
    "    top = scored_sorted.head(top_n)\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78b00a-4eed-430a-b2e1-e2e8d512ba8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26c6d9e0-df38-4abe-ac99-bf6d6dd1471f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:57.005514Z",
     "iopub.status.busy": "2025-12-13T15:30:57.005338Z",
     "iopub.status.idle": "2025-12-13T15:30:57.008345Z",
     "shell.execute_reply": "2025-12-13T15:30:57.007897Z",
     "shell.execute_reply.started": "2025-12-13T15:30:57.005500Z"
    }
   },
   "outputs": [],
   "source": [
    "#full_df = full_df.rename(columns={\"ID\": \"repertoire_id\", \"label_positive\": \"label\"})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f18f9fe3-c55a-4abb-a8a2-afb816e1d6cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T02:53:37.883768Z",
     "iopub.status.busy": "2025-12-02T02:53:37.883608Z",
     "iopub.status.idle": "2025-12-02T02:53:38.128317Z",
     "shell.execute_reply": "2025-12-02T02:53:38.127685Z",
     "shell.execute_reply.started": "2025-12-02T02:53:37.883754Z"
    }
   },
   "source": [
    "all_clone_stats, enriched_public = find_label_enriched_public_clones(\n",
    "    df,\n",
    "    min_pos_repertoires=3,\n",
    "    min_log_odds=1.0,\n",
    "    use_vj=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5469896-30c3-4e1d-bb2a-951f867b25c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:57.008975Z",
     "iopub.status.busy": "2025-12-13T15:30:57.008832Z",
     "iopub.status.idle": "2025-12-13T15:30:57.023448Z",
     "shell.execute_reply": "2025-12-13T15:30:57.022954Z",
     "shell.execute_reply.started": "2025-12-13T15:30:57.008962Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def find_enriched_public_clones(\n",
    "    df,\n",
    "    min_pos_repertoires=3,\n",
    "    min_log_odds=1.0,\n",
    "    use_vj=True,\n",
    "):\n",
    "    df = df.copy()\n",
    "    if use_vj:\n",
    "        df[\"clone_id\"] = (\n",
    "            df[\"junction_aa\"].astype(\"string\")\n",
    "            + \"|\" + df[\"v_call\"].astype(\"string\")\n",
    "            + \"|\" + df[\"j_call\"].astype(\"string\")\n",
    "        )\n",
    "    else:\n",
    "        df[\"clone_id\"] = df[\"junction_aa\"].astype(\"string\")\n",
    "\n",
    "    rep_label = df[[\"ID\", \"label_positive\"]].drop_duplicates(\"ID\")\n",
    "    rep_label[\"label_positive\"] = rep_label[\"label_positive\"].astype(np.int8)\n",
    "\n",
    "    n_pos = int((rep_label[\"label_positive\"] == 1).sum())\n",
    "    n_neg = int((rep_label[\"label_positive\"] == 0).sum())\n",
    "\n",
    "    tmp = df[[\"clone_id\", \"ID\", \"label_positive\"]].drop_duplicates([\"clone_id\", \"ID\"])\n",
    "\n",
    "    ct = pd.crosstab(tmp[\"clone_id\"], tmp[\"label_positive\"])\n",
    "    ct = ct.reindex(columns=[0, 1], fill_value=0).astype(np.int32)\n",
    "    ct = ct.rename(columns={0: \"neg_reps\", 1: \"pos_reps\"})\n",
    "\n",
    "    alpha = 0.5\n",
    "    pos = ct[\"pos_reps\"].to_numpy()\n",
    "    neg = ct[\"neg_reps\"].to_numpy()\n",
    "\n",
    "    log_odds = np.log(\n",
    "        (pos + alpha) / (n_pos - pos + alpha)\n",
    "    ) - np.log(\n",
    "        (neg + alpha) / (n_neg - neg + alpha)\n",
    "    )\n",
    "\n",
    "    ct = ct.assign(log_odds=log_odds, clone_id=ct.index).reset_index(drop=True)\n",
    "\n",
    "    enriched = ct[\n",
    "        (ct[\"pos_reps\"] >= min_pos_repertoires) &\n",
    "        (ct[\"log_odds\"] >= min_log_odds)\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    return ct, enriched\n",
    "\n",
    "def build_public_clone_presence_matrix(df, selected_clone_ids, use_vj=True):\n",
    "    df = df.copy()\n",
    "    if use_vj:\n",
    "        df[\"clone_id\"] = (\n",
    "            df[\"junction_aa\"].astype(\"string\")\n",
    "            + \"|\" + df[\"v_call\"].astype(\"string\")\n",
    "            + \"|\" + df[\"j_call\"].astype(\"string\")\n",
    "        )\n",
    "    else:\n",
    "        df[\"clone_id\"] = df[\"junction_aa\"].astype(\"string\")\n",
    "\n",
    "    df_sel = df[df[\"clone_id\"].isin(selected_clone_ids)].copy()\n",
    "    df_sel = df_sel[[\"ID\", \"clone_id\"]].drop_duplicates()\n",
    "    df_sel[\"value\"] = 1.0\n",
    "\n",
    "    X = (\n",
    "        df_sel\n",
    "        .pivot(index=\"ID\", columns=\"clone_id\", values=\"value\")\n",
    "        .reindex(columns=selected_clone_ids)\n",
    "        .fillna(0.0)\n",
    "        .astype(np.float32)\n",
    "    )\n",
    "    return X\n",
    "\n",
    "def fit_l1_logit_cv(X, y, C=1.0, n_splits=5, random_state=0):\n",
    "    X_values = X.values if hasattr(X, \"values\") else np.asarray(X)\n",
    "    y_values = np.asarray(y).astype(int)\n",
    "\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=n_splits,\n",
    "        shuffle=True,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    oof = np.zeros(len(y_values), dtype=float)\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_values, y_values):\n",
    "        clf = LogisticRegression(\n",
    "            penalty=\"l1\",\n",
    "            C=C,\n",
    "            solver=\"liblinear\",\n",
    "            max_iter=2000,\n",
    "        )\n",
    "        clf.fit(X_values[train_idx], y_values[train_idx])\n",
    "        oof[val_idx] = clf.predict_proba(X_values[val_idx])[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_values, oof)\n",
    "\n",
    "    final_clf = LogisticRegression(\n",
    "        penalty=\"l1\",\n",
    "        C=C,\n",
    "        solver=\"liblinear\",\n",
    "        max_iter=2000,\n",
    "    )\n",
    "    final_clf.fit(X_values, y_values)\n",
    "\n",
    "    return final_clf, auc, oof\n",
    "\n",
    "def run_public_clone_l1_model(df, min_pos_repertoires=3, min_log_odds=1.0, C=1.0):\n",
    "    all_stats, enriched = find_enriched_public_clones(\n",
    "        df,\n",
    "        min_pos_repertoires=min_pos_repertoires,\n",
    "        min_log_odds=min_log_odds,\n",
    "        use_vj=True,\n",
    "    )\n",
    "\n",
    "    selected_clone_ids = enriched[\"clone_id\"]\n",
    "\n",
    "    X_pub = build_public_clone_presence_matrix(\n",
    "        df,\n",
    "        selected_clone_ids,\n",
    "        use_vj=True,\n",
    "    )\n",
    "\n",
    "    y = (\n",
    "        df[[\"ID\", \"label_positive\"]]\n",
    "        .drop_duplicates()\n",
    "        .set_index(\"ID\")[\"label_positive\"]\n",
    "        .astype(int)\n",
    "        .loc[X_pub.index]\n",
    "    )\n",
    "\n",
    "    model, auc, oof = fit_l1_logit_cv(X_pub, y, C=C, n_splits=5, random_state=0)\n",
    "    return model, auc, oof, X_pub, y, all_stats, enriched\n",
    "# Function to perform the full feature selection and training process within CV\n",
    "def run_public_clone_l1_model_no_leak(df, min_pos_repertoires=3, min_log_odds=1.0, C=1.0, n_splits=5, random_state=0):\n",
    "    \n",
    "    # 1. Get repertoire labels (y) and IDs (X index) once\n",
    "    rep_label = df[[\"ID\", \"label_positive\"]].drop_duplicates(\"ID\").set_index(\"ID\")\n",
    "    y = rep_label[\"label_positive\"].astype(int)\n",
    "    \n",
    "    # 2. Get unique repertoire IDs to use for CV split\n",
    "    rep_ids = rep_label.index.to_numpy() \n",
    "    y_values = y.to_numpy() \n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    oof = np.zeros(len(y_values), dtype=float)\n",
    "\n",
    "    # 3. Iterate over the folds\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(rep_ids, y_values)):\n",
    "        # Get repertoire IDs for training and validation sets\n",
    "        train_rep_ids = rep_ids[train_idx]\n",
    "        val_rep_ids = rep_ids[val_idx]\n",
    "\n",
    "        # --- A. FEATURE SELECTION ON TRAINING DATA ONLY ---\n",
    "        df_train = df[df[\"ID\"].isin(train_rep_ids)].copy() \n",
    "        df_val = df[df[\"ID\"].isin(val_rep_ids)].copy()\n",
    "        \n",
    "        # Select enriched clones based *ONLY* on the training data\n",
    "        _, enriched_train = find_enriched_public_clones(\n",
    "            df_train,\n",
    "            min_pos_repertoires=min_pos_repertoires,\n",
    "            min_log_odds=min_log_odds,\n",
    "            use_vj=True,\n",
    "        )\n",
    "        selected_clone_ids = enriched_train[\"clone_id\"]\n",
    "\n",
    "        # --- B. FEATURE TRANSFORMATION ON TRAIN/VAL DATA ---\n",
    "        # Build feature matrix for TRAIN and VAL using the features selected on TRAIN\n",
    "        X_train = build_public_clone_presence_matrix(df_train, selected_clone_ids, use_vj=True)\n",
    "        X_val = build_public_clone_presence_matrix(df_val, selected_clone_ids, use_vj=True)\n",
    "\n",
    "        # Ensure y_train and y_val align with X_train and X_val indices\n",
    "        y_train = y.loc[X_train.index]\n",
    "        y_val = y.loc[X_val.index]\n",
    "\n",
    "        # --- C. MODEL FITTING AND PREDICTION ---\n",
    "        clf = LogisticRegression(\n",
    "            penalty=\"l1\",\n",
    "            C=C,\n",
    "            solver=\"liblinear\",\n",
    "            max_iter=10000,\n",
    "        )\n",
    "        clf.fit(X_train.values, y_train.values)\n",
    "        \n",
    "        # Store predictions for OOF calculation\n",
    "        # The indices (val_idx) are based on the original rep_ids/y_values array order\n",
    "        val_map = {id_: idx for idx, id_ in zip(val_idx, y_val.index)}\n",
    "        original_val_indices = np.array([val_map[id_] for id_ in X_val.index])\n",
    "        oof[original_val_indices] = clf.predict_proba(X_val.values)[:, 1]\n",
    "\n",
    "    # Final OOF AUC\n",
    "    auc = roc_auc_score(y_values, oof)\n",
    "    \n",
    "    # You would still need to train the final model on all data *after* selecting \n",
    "    # features on all data, but the OOF AUC is now unbiased.\n",
    "    # The final model training (on ALL data) remains the same as your original run_public_clone_l1_model, \n",
    "    # but for an unbiased performance estimate, the OOF AUC is the key.\n",
    "    # The original logic for final model training can be put here if needed.\n",
    "    \n",
    "    return auc, oof"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95de1124-bef0-4288-8799-95f9ce9bf03a",
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-02T02:53:19.297Z",
     "iopub.execute_input": "2025-12-02T02:49:08.177299Z",
     "iopub.status.busy": "2025-12-02T02:49:08.177067Z"
    }
   },
   "source": [
    "model, auc, oof, X_pub, y_pub, all_stats, enriched_public = run_public_clone_l1_model_no_leak(full_df)\n",
    "print(\"cv auc:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2a9b848-7bfa-4c1e-9e31-3e45470fa6a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:57.024140Z",
     "iopub.status.busy": "2025-12-13T15:30:57.023993Z",
     "iopub.status.idle": "2025-12-13T15:30:57.034637Z",
     "shell.execute_reply": "2025-12-13T15:30:57.034161Z",
     "shell.execute_reply.started": "2025-12-13T15:30:57.024128Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def find_enriched_public_clones(\n",
    "    df,\n",
    "    min_pos_repertoires=3,\n",
    "    min_log_odds=1.0,\n",
    "    use_vj=True,\n",
    "):\n",
    "    df = df.copy()\n",
    "    if use_vj:\n",
    "        df[\"clone_id\"] = (\n",
    "            df[\"junction_aa\"].astype(\"string\")\n",
    "            + \"|\" + df[\"v_call\"].astype(\"string\")\n",
    "            + \"|\" + df[\"j_call\"].astype(\"string\")\n",
    "        )\n",
    "    else:\n",
    "        df[\"clone_id\"] = df[\"junction_aa\"].astype(\"string\")\n",
    "\n",
    "    rep_label = df[[\"ID\", \"label_positive\"]].drop_duplicates(\"ID\")\n",
    "    rep_label[\"label_positive\"] = rep_label[\"label_positive\"].astype(np.int8)\n",
    "\n",
    "    n_pos = int((rep_label[\"label_positive\"] == 1).sum())\n",
    "    n_neg = int((rep_label[\"label_positive\"] == 0).sum())\n",
    "\n",
    "    tmp = df[[\"clone_id\", \"ID\", \"label_positive\"]].drop_duplicates([\"clone_id\", \"ID\"])\n",
    "\n",
    "    ct = pd.crosstab(tmp[\"clone_id\"], tmp[\"label_positive\"])\n",
    "    ct = ct.reindex(columns=[0, 1], fill_value=0).astype(np.int32)\n",
    "    ct = ct.rename(columns={0: \"neg_reps\", 1: \"pos_reps\"})\n",
    "\n",
    "    alpha = 0.5\n",
    "    pos = ct[\"pos_reps\"].to_numpy()\n",
    "    neg = ct[\"neg_reps\"].to_numpy()\n",
    "\n",
    "    log_odds = np.log(\n",
    "        (pos + alpha) / (n_pos - pos + alpha)\n",
    "    ) - np.log(\n",
    "        (neg + alpha) / (n_neg - neg + alpha)\n",
    "    )\n",
    "\n",
    "    ct = ct.assign(log_odds=log_odds, clone_id=ct.index).reset_index(drop=True)\n",
    "\n",
    "    enriched = ct[\n",
    "        (ct[\"pos_reps\"] >= min_pos_repertoires) &\n",
    "        (ct[\"log_odds\"] >= min_log_odds)\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    return ct, enriched\n",
    "\n",
    "\n",
    "def build_public_clone_presence_matrix(df, selected_clone_ids, use_vj=True):\n",
    "    df = df.copy()\n",
    "    if use_vj:\n",
    "        df[\"clone_id\"] = (\n",
    "            df[\"junction_aa\"].astype(\"string\")\n",
    "            + \"|\" + df[\"v_call\"].astype(\"string\")\n",
    "            + \"|\" + df[\"j_call\"].astype(\"string\")\n",
    "        )\n",
    "    else:\n",
    "        df[\"clone_id\"] = df[\"junction_aa\"].astype(\"string\")\n",
    "\n",
    "    df_sel = df[df[\"clone_id\"].isin(selected_clone_ids)].copy()\n",
    "    df_sel = df_sel[[\"ID\", \"clone_id\"]].drop_duplicates()\n",
    "    df_sel[\"value\"] = 1.0\n",
    "\n",
    "    X = (\n",
    "        df_sel\n",
    "        .pivot(index=\"ID\", columns=\"clone_id\", values=\"value\")\n",
    "        .reindex(columns=selected_clone_ids)\n",
    "        .fillna(0.0)\n",
    "        .astype(np.float32)\n",
    "    )\n",
    "    return X\n",
    "\n",
    "\n",
    "def _run_fold(\n",
    "    fold_id,\n",
    "    train_ids,\n",
    "    val_ids,\n",
    "    df,\n",
    "    C,\n",
    "    min_pos_repertoires,\n",
    "    min_log_odds,\n",
    "    use_vj,\n",
    "):\n",
    "    print(f\"[fold {fold_id+1}] start: n_train_ids={len(train_ids)}, n_val_ids={len(val_ids)}\")\n",
    "\n",
    "    df_train = df[df[\"ID\"].isin(train_ids)]\n",
    "    df_val = df[df[\"ID\"].isin(val_ids)]\n",
    "\n",
    "    all_stats_tr, enriched_tr = find_enriched_public_clones(\n",
    "        df_train,\n",
    "        min_pos_repertoires=min_pos_repertoires,\n",
    "        min_log_odds=min_log_odds,\n",
    "        use_vj=use_vj,\n",
    "    )\n",
    "    selected = enriched_tr[\"clone_id\"]\n",
    "    n_sel = len(selected)\n",
    "\n",
    "    if n_sel == 0:\n",
    "        rep_label_val = (\n",
    "            df_val[[\"ID\", \"label_positive\"]]\n",
    "            .drop_duplicates(\"ID\")\n",
    "            .set_index(\"ID\")[\"label_positive\"]\n",
    "            .astype(int)\n",
    "        )\n",
    "        base_rate = rep_label_val.mean()\n",
    "        val_pred = np.full(len(rep_label_val), base_rate, dtype=float)\n",
    "        fold_auc = roc_auc_score(rep_label_val.values, val_pred)\n",
    "        print(f\"[fold {fold_id+1}] auc={fold_auc:.4f}, n_selected={n_sel} (constant preds)\")\n",
    "        return fold_id, rep_label_val.index.to_numpy(), val_pred, fold_auc, n_sel\n",
    "\n",
    "    X_train = build_public_clone_presence_matrix(df_train, selected, use_vj=use_vj)\n",
    "    X_val = build_public_clone_presence_matrix(df_val, selected, use_vj=use_vj)\n",
    "\n",
    "    y_train = (\n",
    "        df_train[[\"ID\", \"label_positive\"]]\n",
    "        .drop_duplicates(\"ID\")\n",
    "        .set_index(\"ID\")[\"label_positive\"]\n",
    "        .astype(int)\n",
    "        .loc[X_train.index]\n",
    "    )\n",
    "    y_val = (\n",
    "        df_val[[\"ID\", \"label_positive\"]]\n",
    "        .drop_duplicates(\"ID\")\n",
    "        .set_index(\"ID\")[\"label_positive\"]\n",
    "        .astype(int)\n",
    "        .loc[X_val.index]\n",
    "    )\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        penalty=\"l1\",\n",
    "        C=C,\n",
    "        solver=\"liblinear\",\n",
    "        max_iter=10000,\n",
    "    )\n",
    "    clf.fit(X_train.values, y_train.values)\n",
    "    val_pred = clf.predict_proba(X_val.values)[:, 1]\n",
    "    fold_auc = roc_auc_score(y_val.values, val_pred)\n",
    "\n",
    "    print(f\"[fold {fold_id+1}] auc={fold_auc:.4f}, n_selected={n_sel}\")\n",
    "    return fold_id, y_val.index.to_numpy(), val_pred, fold_auc, n_sel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f21eabd-4c17-49a8-894d-ca21aad5bdfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:57.035219Z",
     "iopub.status.busy": "2025-12-13T15:30:57.035076Z",
     "iopub.status.idle": "2025-12-13T15:30:57.042747Z",
     "shell.execute_reply": "2025-12-13T15:30:57.042360Z",
     "shell.execute_reply.started": "2025-12-13T15:30:57.035207Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_public_clone_model(df_test, final_clf, enriched_public, use_vj=True):\n",
    "    df_test = df_test.copy()\n",
    "    rep_ids = df_test[\"ID\"].drop_duplicates().to_numpy()\n",
    "\n",
    "    if enriched_public is None or len(enriched_public) == 0:\n",
    "        X_test = pd.DataFrame(\n",
    "            {\"bias\": np.ones(len(rep_ids), dtype=np.float32)},\n",
    "            index=rep_ids,\n",
    "        )\n",
    "    else:\n",
    "        selected_clone_ids = enriched_public[\"clone_id\"]\n",
    "        X_test = build_public_clone_presence_matrix(\n",
    "            df_test,\n",
    "            selected_clone_ids=selected_clone_ids,\n",
    "            use_vj=use_vj,\n",
    "        )\n",
    "        missing_ids = [rid for rid in rep_ids if rid not in X_test.index]\n",
    "        if len(missing_ids) > 0:\n",
    "            extra = pd.DataFrame(\n",
    "                0.0,\n",
    "                index=missing_ids,\n",
    "                columns=X_test.columns,\n",
    "                dtype=np.float32,\n",
    "            )\n",
    "            X_test = (\n",
    "                pd.concat([X_test, extra], axis=0)\n",
    "                .loc[rep_ids]\n",
    "            )\n",
    "\n",
    "    test_pred = final_clf.predict_proba(X_test.values)[:, 1]\n",
    "    pred_df = pd.DataFrame(\n",
    "        {\"ID\": X_test.index.to_numpy(), \"pred_public\": test_pred}\n",
    "    )\n",
    "    return pred_df, X_test\n",
    "def stats_to_seq_table(stats_df, dataset_name, start_rank=1):\n",
    "    df = stats_df.copy().reset_index(drop=True)\n",
    "\n",
    "    # split clone_id -> junction_aa, v_call, j_call\n",
    "    split = df[\"clone_id\"].astype(str).str.split(\"|\", n=2, expand=True)\n",
    "    df[\"junction_aa\"] = split[0]\n",
    "    df[\"v_call\"] = split[1]\n",
    "    df[\"j_call\"] = split[2]\n",
    "\n",
    "    # rank for constructing ID\n",
    "    ranks = np.arange(start_rank, start_rank + len(df))\n",
    "\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"ID\": [f\"{dataset_name}_seq_top_{r}\" for r in ranks],\n",
    "            \"dataset\": dataset_name,\n",
    "            \"label_positive_probability\": -999.0,\n",
    "            \"junction_aa\": df[\"junction_aa\"].values,\n",
    "            \"v_call\": df[\"v_call\"].values,\n",
    "            \"j_call\": df[\"j_call\"].values,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return out\n",
    "def preds_to_submission(pred_df, dataset_name):\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"ID\": pred_df[\"ID\"].values,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"label_positive_probability\": pred_df[\"pred_public\"].astype(float).values,\n",
    "            \"junction_aa\": -999.0,\n",
    "            \"v_call\": -999.0,\n",
    "            \"j_call\": -999.0,\n",
    "        }\n",
    "    )\n",
    "    return out\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "def eval_param_combo(df, min_pos, min_lo, C, n_splits=5, random_state=0):\n",
    "    print(f\"=== combo: min_pos={min_pos}, min_log_odds={min_lo}, C={C} ===\")\n",
    "    final_clf, cv_auc, oof, X_pub, y_pub, all_stats, enriched_public, fold_aucs = run_public_clone_l1_cv_noleak(\n",
    "        df,\n",
    "        min_pos_repertoires=min_pos,\n",
    "        min_log_odds=min_lo,\n",
    "        C=C,\n",
    "        n_splits=n_splits,\n",
    "        n_jobs=1,\n",
    "        use_vj=True,\n",
    "    )\n",
    "    print(f\"=== combo done: min_pos={min_pos}, min_log_odds={min_lo}, C={C}, cv_auc={cv_auc:.4f} ===\")\n",
    "    return {\n",
    "        \"min_pos\": min_pos,\n",
    "        \"min_log_odds\": min_lo,\n",
    "        \"C\": C,\n",
    "        \"cv_auc\": cv_auc,\n",
    "        \"fold_aucs\": fold_aucs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cad77da8-d5b5-4f0c-9145-14f7b5224e74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T02:43:51.739842Z",
     "iopub.status.busy": "2025-12-03T02:43:51.739571Z",
     "iopub.status.idle": "2025-12-03T02:44:05.477372Z",
     "shell.execute_reply": "2025-12-03T02:44:05.476729Z",
     "shell.execute_reply.started": "2025-12-03T02:43:51.739825Z"
    }
   },
   "source": [
    "full_df = load_full_dataset('train_datasets/train_datasets/train_dataset_3')\n",
    "unique_seqs = full_df[[\"junction_aa\", \"v_call\", \"j_call\"]].drop_duplicates()\n",
    "\n",
    "min_pos_values = [ 2,3,4,5,7,8,9]\n",
    "min_log_odds_values = [1.0, 1.25, 1.5]\n",
    "C_values = [ 1.0,2.0, 3.0]\n",
    "\n",
    "param_grid = [\n",
    "    (min_pos, min_lo, C)\n",
    "    for min_pos in min_pos_values\n",
    "    for min_lo in min_log_odds_values\n",
    "    for C in C_values\n",
    "]\n",
    "\n",
    "results = Parallel(n_jobs=32)(\n",
    "    delayed(eval_param_combo)(full_df, min_pos, min_lo, C)\n",
    "    for (min_pos, min_lo, C) in param_grid\n",
    ")\n",
    "\n",
    "results_sorted = sorted(results, key=lambda r: r[\"cv_auc\"], reverse=True)\n",
    "\n",
    "print(\"\\nTop combos:\")\n",
    "for r in results_sorted[:10]:\n",
    "    print(\n",
    "        f\"min_pos={r['min_pos']}, \"\n",
    "        f\"min_log_odds={r['min_log_odds']}, \"\n",
    "        f\"C={r['C']}, \"\n",
    "        f\"cv_auc={r['cv_auc']:.4f}\")\n",
    "\n",
    "\n",
    "#change param here from the best result above \n",
    "best_min_pos = 6\n",
    "best_min_log_odds = 1.5\n",
    "best_C = 3.0\n",
    "\n",
    "final_clf, cv_auc, oof_public, X_pub, y_pub, all_stats, enriched_public, fold_aucs = run_public_clone_l1_cv_noleak(\n",
    "    full_df,\n",
    "    min_pos_repertoires=best_min_pos,\n",
    "    min_log_odds=best_min_log_odds,\n",
    "    C=best_C,\n",
    "    n_splits=5,\n",
    "    n_jobs=-1,\n",
    "    use_vj=True,\n",
    ")\n",
    "\n",
    "print(\"final cv auc:\", cv_auc)\n",
    "print(\"n_selected_full:\", len(enriched_public))\n",
    "\n",
    "df_test = load_full_dataset('test_datasets/test_datasets/test_dataset_3')\n",
    "\n",
    "\n",
    "pred_test_public, X_test_public = predict_public_clone_model(\n",
    "    df_test,\n",
    "    final_clf=final_clf,\n",
    "    enriched_public=enriched_public,\n",
    "    use_vj=True,\n",
    ")\n",
    "\n",
    "if \"label_positive\" in df_test.columns:\n",
    "    y_test = (\n",
    "        df_test[[\"ID\", \"label_positive\"]]\n",
    "        .drop_duplicates(\"ID\")\n",
    "        .set_index(\"ID\")[\"label_positive\"]\n",
    "        .astype(int)\n",
    "        .loc[pred_test_public[\"ID\"]]\n",
    "        .to_numpy()\n",
    "    )\n",
    "    test_auc_public = roc_auc_score(y_test, pred_test_public[\"pred_public\"])\n",
    "    print(\"test auc (public clone model):\", test_auc_public)\n",
    "\n",
    "\n",
    "sub_test_public = preds_to_submission(\n",
    "    pred_test_public,\n",
    "    dataset_name=\"test_dataset_2\",\n",
    ")\n",
    "\n",
    "\n",
    "n_top = 50000\n",
    "\n",
    "all_stats_sorted = all_stats.sort_values(\"log_odds\", ascending=False)\n",
    "\n",
    "enriched_ids = set(enriched_public[\"clone_id\"])\n",
    "\n",
    "extra_needed = max(0, n_top - len(enriched_ids))\n",
    "\n",
    "extra_stats = all_stats_sorted[~all_stats_sorted[\"clone_id\"].isin(enriched_ids)].head(extra_needed)\n",
    "\n",
    "top_stats_with_enriched = pd.concat(\n",
    "    [enriched_public, extra_stats],\n",
    "    ignore_index=True\n",
    ").drop_duplicates(\"clone_id\")\n",
    "\n",
    "print(len(enriched_public), len(top_stats_with_enriched))\n",
    "\n",
    "seq_table = stats_to_seq_table(\n",
    "    top_stats_with_enriched,\n",
    "    dataset_name=\"train_dataset_1\",  # or \"train_dataset_2\", etc.\n",
    "    start_rank=1,\n",
    ")\n",
    "\n",
    "seq_table.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cee7dbc8-69fd-48fa-bfa4-833b18b16d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T04:30:09.816620Z",
     "iopub.status.busy": "2025-12-03T04:30:09.816316Z",
     "iopub.status.idle": "2025-12-03T04:33:06.110373Z",
     "shell.execute_reply": "2025-12-03T04:33:06.108407Z",
     "shell.execute_reply.started": "2025-12-03T04:30:09.816580Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "log_file = \"training_auc_05A_log.tsv\"\n",
    "\n",
    "pairs = [\n",
    "    (\"train_datasets/train_datasets/train_dataset_1\",\n",
    "     [\"test_datasets/test_datasets/test_dataset_1\"]),\n",
    "    (\"train_datasets/train_datasets/train_dataset_3\",\n",
    "     [\"test_datasets/test_datasets/test_dataset_3\"]),\n",
    "]\n",
    "\n",
    "min_pos_values = [2, 3, 4, 5, 6, 7, 8, 9]\n",
    "min_log_odds_values = [0.75, 1.0, 1.25, 1.5, 1.75]\n",
    "C_values = [0.5, 1.0, 2.0, 3.0, 5.0]\n",
    "penalty_options = [\"l1\", \"l2\", \"elasticnet\"]\n",
    "class_weight_options = [None, \"balanced\"]\n",
    "l1_ratio_options = [0.2, 0.5, 0.8]\n",
    "\n",
    "N_TRIALS = 200          # number of random combos to evaluate\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 123\n",
    "\n",
    "# parallelism: we parallelize over combos, CV inside each combo is sequential (n_jobs=1)\n",
    "N_FOLD_JOBS = 1         # jobs inside run_public_clone_l1_cv_noleak\n",
    "N_TRIAL_JOBS = 60       # how many combos to evaluate in parallel\n",
    "\n",
    "submission_out_dir = \"results_05A_Pub_Clones\"\n",
    "important_out_dir = \"results_05A_Pub_Clones\"\n",
    "\n",
    "os.makedirs(submission_out_dir, exist_ok=True)\n",
    "os.makedirs(important_out_dir, exist_ok=True)\n",
    "\n",
    "# build full discrete param grid\n",
    "param_grid = []\n",
    "for min_pos in min_pos_values:\n",
    "    for min_lo in min_log_odds_values:\n",
    "        for C in C_values:\n",
    "            for penalty in penalty_options:\n",
    "                for class_weight in class_weight_options:\n",
    "                    if penalty == \"elasticnet\":\n",
    "                        for l1_ratio in l1_ratio_options:\n",
    "                            param_grid.append(\n",
    "                                (min_pos, min_lo, C, penalty, class_weight, l1_ratio)\n",
    "                            )\n",
    "                    else:\n",
    "                        param_grid.append(\n",
    "                            (min_pos, min_lo, C, penalty, class_weight, None)\n",
    "                        )\n",
    "\n",
    "def eval_param_combo(full_df, combo, trial_idx, total_trials):\n",
    "    min_pos, min_lo, C, penalty, class_weight, l1_ratio = combo\n",
    "\n",
    "    final_clf, cv_auc, oof, X_pub, y_pub, all_stats, enriched_public, fold_aucs = run_public_clone_l1_cv_noleak(\n",
    "        full_df,\n",
    "        min_pos_repertoires=min_pos,\n",
    "        min_log_odds=min_lo,\n",
    "        C=C,\n",
    "        n_splits=N_SPLITS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=N_FOLD_JOBS,\n",
    "        use_vj=True,\n",
    "        penalty_cv=penalty,\n",
    "        penalty_final=penalty,\n",
    "        class_weight=class_weight,\n",
    "        l1_ratio_cv=l1_ratio,\n",
    "        l1_ratio_final=l1_ratio,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"[combo {trial_idx+1}/{total_trials}] \"\n",
    "        f\"min_pos={min_pos}, min_log_odds={min_lo}, C={C}, \"\n",
    "        f\"penalty={penalty}, class_weight={class_weight}, l1_ratio={l1_ratio}, \"\n",
    "        f\"cv_auc={cv_auc:.4f}\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"min_pos\": min_pos,\n",
    "        \"min_log_odds\": min_lo,\n",
    "        \"C\": C,\n",
    "        \"penalty\": penalty,\n",
    "        \"class_weight\": class_weight,\n",
    "        \"l1_ratio\": l1_ratio,\n",
    "        \"cv_auc\": cv_auc,\n",
    "        \"fold_aucs\": fold_aucs,\n",
    "        \"final_clf\": final_clf,\n",
    "        \"X_pub\": X_pub,\n",
    "        \"y_pub\": y_pub,\n",
    "        \"all_stats\": all_stats,\n",
    "        \"enriched_public\": enriched_public,\n",
    "    }\n",
    "\n",
    "for train_dir, test_dirs in pairs:\n",
    "    train_name = os.path.basename(train_dir)\n",
    "    imp_out_path = os.path.join(important_out_dir, f\"{train_name}_top_sequences.tsv\")\n",
    "\n",
    "    submission_paths = [\n",
    "        os.path.join(submission_out_dir, f\"{os.path.basename(td)}_submission.tsv\")\n",
    "        for td in test_dirs\n",
    "    ]\n",
    "\n",
    "    if os.path.exists(imp_out_path) and all(os.path.exists(p) for p in submission_paths):\n",
    "        print(f\"Skipping {train_name}: all outputs already exist.\")\n",
    "        continue\n",
    "\n",
    "    full_df = load_full_dataset(train_dir)\n",
    "\n",
    "    print(f\"Starting random search for {train_name}\")\n",
    "    random.seed(RANDOM_STATE)\n",
    "\n",
    "    # sample combos for random search\n",
    "    if len(param_grid) <= N_TRIALS:\n",
    "        sampled_combos = param_grid\n",
    "    else:\n",
    "        sampled_combos = random.sample(param_grid, N_TRIALS)\n",
    "\n",
    "    total_trials = len(sampled_combos)\n",
    "\n",
    "    # evaluate combos in parallel\n",
    "    results = Parallel(n_jobs=N_TRIAL_JOBS)(\n",
    "        delayed(eval_param_combo)(full_df, combo, i, total_trials)\n",
    "        for i, combo in enumerate(sampled_combos)\n",
    "    )\n",
    "\n",
    "    # pick best by cv_auc\n",
    "    results_sorted = sorted(results, key=lambda r: r[\"cv_auc\"], reverse=True)\n",
    "    best = results_sorted[0]\n",
    "\n",
    "    best_min_pos = best[\"min_pos\"]\n",
    "    best_min_log_odds = best[\"min_log_odds\"]\n",
    "    best_C = best[\"C\"]\n",
    "    best_penalty = best[\"penalty\"]\n",
    "    best_class_weight = best[\"class_weight\"]\n",
    "    best_l1_ratio = best[\"l1_ratio\"]\n",
    "    cv_auc = best[\"cv_auc\"]\n",
    "\n",
    "    print(\n",
    "        f\"{train_name} best params: \"\n",
    "        f\"min_pos={best_min_pos}, \"\n",
    "        f\"min_log_odds={best_min_log_odds}, \"\n",
    "        f\"C={best_C}, \"\n",
    "        f\"penalty={best_penalty}, \"\n",
    "        f\"class_weight={best_class_weight}, \"\n",
    "        f\"l1_ratio={best_l1_ratio}, \"\n",
    "        f\"cv_auc={cv_auc:.4f}\"\n",
    "    )\n",
    "\n",
    "    # retrain final model on full data with best params\n",
    "    final_clf, cv_auc_full, oof_public, X_pub, y_pub, all_stats, enriched_public, fold_aucs = run_public_clone_l1_cv_noleak(\n",
    "        full_df,\n",
    "        min_pos_repertoires=best_min_pos,\n",
    "        min_log_odds=best_min_log_odds,\n",
    "        C=best_C,\n",
    "        n_splits=N_SPLITS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=N_FOLD_JOBS,\n",
    "        use_vj=True,\n",
    "        penalty_cv=best_penalty,\n",
    "        penalty_final=best_penalty,\n",
    "        class_weight=best_class_weight,\n",
    "        l1_ratio_cv=best_l1_ratio,\n",
    "        l1_ratio_final=best_l1_ratio,\n",
    "    )\n",
    "\n",
    "    print(f\"{train_name} final cv auc (re-fit): {cv_auc_full:.4f}\")\n",
    "\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(\n",
    "            f\"{train_name}\\t\"\n",
    "            f\"{best_min_pos}\\t\"\n",
    "            f\"{best_min_log_odds}\\t\"\n",
    "            f\"{best_C}\\t\"\n",
    "            f\"{best_penalty}\\t\"\n",
    "            f\"{best_class_weight}\\t\"\n",
    "            f\"{best_l1_ratio}\\t\"\n",
    "            f\"{cv_auc_full}\\n\"\n",
    "        )\n",
    "\n",
    "    for test_dir in test_dirs:\n",
    "        test_name = os.path.basename(test_dir)\n",
    "        out_path = os.path.join(submission_out_dir, f\"{test_name}_submission.tsv\")\n",
    "\n",
    "        if os.path.exists(out_path):\n",
    "            print(f\"Skipping {test_name}: submission already exists.\")\n",
    "            continue\n",
    "\n",
    "        df_test = load_full_dataset(test_dir)\n",
    "\n",
    "        pred_test_public, X_test_public = predict_public_clone_model(\n",
    "            df_test,\n",
    "            final_clf=final_clf,\n",
    "            enriched_public=enriched_public,\n",
    "            use_vj=True,\n",
    "        )\n",
    "\n",
    "        if \"label_positive\" in df_test.columns:\n",
    "            y_test = (\n",
    "                df_test[[\"ID\", \"label_positive\"]]\n",
    "                .drop_duplicates(\"ID\")\n",
    "                .set_index(\"ID\")[\"label_positive\"]\n",
    "                .astype(int)\n",
    "                .loc[pred_test_public[\"ID\"]]\n",
    "                .to_numpy()\n",
    "            )\n",
    "            test_auc_public = roc_auc_score(y_test, pred_test_public[\"pred_public\"])\n",
    "            print(f\"{test_name} test auc (public clone model): {test_auc_public:.4f}\")\n",
    "            with open(log_file, \"a\") as f:\n",
    "                f.write(\n",
    "                    f\"{train_name}\\t\"\n",
    "                    f\"{test_name}\\t\"\n",
    "                    f\"test_auc_public\\t\"\n",
    "                    f\"{test_auc_public}\\n\"\n",
    "                )\n",
    "\n",
    "        sub_test_public = preds_to_submission(\n",
    "            pred_test_public,\n",
    "            dataset_name=test_name,\n",
    "        )\n",
    "\n",
    "        sub_test_public.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "        print(f\"wrote {out_path}\")\n",
    "\n",
    "    if not os.path.exists(imp_out_path):\n",
    "        n_top = 50000\n",
    "\n",
    "        all_stats_sorted = all_stats.sort_values(\"log_odds\", ascending=False)\n",
    "        enriched_ids = set(enriched_public[\"clone_id\"])\n",
    "        extra_needed = max(0, n_top - len(enriched_ids))\n",
    "\n",
    "        extra_stats = all_stats_sorted[\n",
    "            ~all_stats_sorted[\"clone_id\"].isin(enriched_ids)\n",
    "        ].head(extra_needed)\n",
    "\n",
    "        top_stats_with_enriched = pd.concat(\n",
    "            [enriched_public, extra_stats],\n",
    "            ignore_index=True\n",
    "        ).drop_duplicates(\"clone_id\")\n",
    "\n",
    "        print(len(enriched_public), len(top_stats_with_enriched))\n",
    "\n",
    "        seq_table = stats_to_seq_table(\n",
    "            top_stats_with_enriched,\n",
    "            dataset_name=train_name,\n",
    "            start_rank=1,\n",
    "        )\n",
    "\n",
    "        seq_table.to_csv(imp_out_path, sep=\"\\t\", index=False)\n",
    "        print(f\"wrote {imp_out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8804aa0e-0695-4b78-a1ab-fbcb017299ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:57.043424Z",
     "iopub.status.busy": "2025-12-13T15:30:57.043263Z",
     "iopub.status.idle": "2025-12-13T15:30:57.056801Z",
     "shell.execute_reply": "2025-12-13T15:30:57.056440Z",
     "shell.execute_reply.started": "2025-12-13T15:30:57.043392Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def _make_logreg(penalty, C, class_weight, l1_ratio):\n",
    "    if penalty == \"elasticnet\":\n",
    "        if l1_ratio is None:\n",
    "            l1_ratio = 0.5\n",
    "        return LogisticRegression(\n",
    "            penalty=\"elasticnet\",\n",
    "            C=C,\n",
    "            solver=\"saga\",\n",
    "            max_iter=10000,\n",
    "            class_weight=class_weight,\n",
    "            l1_ratio=l1_ratio,\n",
    "        )\n",
    "    elif penalty in (\"l1\", \"l2\"):\n",
    "        return LogisticRegression(\n",
    "            penalty=penalty,\n",
    "            C=C,\n",
    "            solver=\"liblinear\",\n",
    "            max_iter=10000,\n",
    "            class_weight=class_weight,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"unsupported penalty: {penalty}\")\n",
    "\n",
    "\n",
    "def _run_fold(\n",
    "    fold_id,\n",
    "    train_ids,\n",
    "    val_ids,\n",
    "    df,\n",
    "    C,\n",
    "    min_pos_repertoires,\n",
    "    min_log_odds,\n",
    "    use_vj,\n",
    "    penalty_cv=\"l1\",\n",
    "    class_weight=None,\n",
    "    l1_ratio_cv=None,\n",
    "    extra_clone_ids=None,\n",
    "):\n",
    "    print(f\"[fold {fold_id+1}] start: n_train_ids={len(train_ids)}, n_val_ids={len(val_ids)}\")\n",
    "\n",
    "    df_train = df[df[\"ID\"].isin(train_ids)]\n",
    "    df_val = df[df[\"ID\"].isin(val_ids)]\n",
    "\n",
    "    all_stats_tr, enriched_tr = find_enriched_public_clones(\n",
    "        df_train,\n",
    "        min_pos_repertoires=min_pos_repertoires,\n",
    "        min_log_odds=min_log_odds,\n",
    "        use_vj=use_vj,\n",
    "        extra_clone_ids=extra_clone_ids,\n",
    "    )\n",
    "    selected = enriched_tr[\"clone_id\"]\n",
    "    n_sel = len(selected)\n",
    "\n",
    "    if n_sel == 0:\n",
    "        rep_label_val = (\n",
    "            df_val[[\"ID\", \"label_positive\"]]\n",
    "            .drop_duplicates(\"ID\")\n",
    "            .set_index(\"ID\")[\"label_positive\"]\n",
    "            .astype(int)\n",
    "        )\n",
    "        base_rate = rep_label_val.mean()\n",
    "        val_pred = np.full(len(rep_label_val), base_rate, dtype=float)\n",
    "        fold_auc = roc_auc_score(rep_label_val.values, val_pred)\n",
    "        print(f\"[fold {fold_id+1}] auc={fold_auc:.4f}, n_selected={n_sel} (constant preds)\")\n",
    "        return fold_id, rep_label_val.index.to_numpy(), val_pred, fold_auc, n_sel\n",
    "\n",
    "    X_train = build_public_clone_presence_matrix(df_train, selected, use_vj=use_vj)\n",
    "    X_val = build_public_clone_presence_matrix(df_val, selected, use_vj=use_vj)\n",
    "\n",
    "    y_train = (\n",
    "        df_train[[\"ID\", \"label_positive\"]]\n",
    "        .drop_duplicates(\"ID\")\n",
    "        .set_index(\"ID\")[\"label_positive\"]\n",
    "        .astype(int)\n",
    "        .loc[X_train.index]\n",
    "    )\n",
    "    y_val = (\n",
    "        df_val[[\"ID\", \"label_positive\"]]\n",
    "        .drop_duplicates(\"ID\")\n",
    "        .set_index(\"ID\")[\"label_positive\"]\n",
    "        .astype(int)\n",
    "        .loc[X_val.index]\n",
    "    )\n",
    "\n",
    "    clf = _make_logreg(\n",
    "        penalty=penalty_cv,\n",
    "        C=C,\n",
    "        class_weight=class_weight,\n",
    "        l1_ratio=l1_ratio_cv,\n",
    "    )\n",
    "    clf.fit(X_train.values, y_train.values)\n",
    "    val_pred = clf.predict_proba(X_val.values)[:, 1]\n",
    "    fold_auc = roc_auc_score(y_val.values, val_pred)\n",
    "\n",
    "    print(f\"[fold {fold_id+1}] auc={fold_auc:.4f}, n_selected={n_sel}\")\n",
    "    return fold_id, y_val.index.to_numpy(), val_pred, fold_auc, n_sel\n",
    "\n",
    "\n",
    "def run_public_clone_l1_cv_noleak(\n",
    "    df,\n",
    "    min_pos_repertoires=3,\n",
    "    min_log_odds=1.0,\n",
    "    C=1.0,\n",
    "    n_splits=5,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    use_vj=True,\n",
    "    penalty_cv=\"l1\",\n",
    "    penalty_final=None,\n",
    "    class_weight=None,\n",
    "    l1_ratio_cv=None,\n",
    "    l1_ratio_final=None,\n",
    "    extra_clone_ids=None,\n",
    "):\n",
    "    rep_label = df[[\"ID\", \"label_positive\"]].drop_duplicates(\"ID\")\n",
    "    rep_label[\"label_positive\"] = rep_label[\"label_positive\"].astype(int)\n",
    "    ids = rep_label[\"ID\"].to_numpy()\n",
    "    y = rep_label[\"label_positive\"].to_numpy().astype(int)\n",
    "\n",
    "    counts = np.bincount(y, minlength=2)\n",
    "    if (counts > 0).sum() < 2:\n",
    "        return None, -1.0, None, None, None, None, None, []\n",
    "    \n",
    "    n_splits = min(n_splits, int(counts.min()))\n",
    "    if n_splits < 2:\n",
    "        return None, -1.0, None, None, None, None, None, []\n",
    "    id_to_idx = {rid: i for i, rid in enumerate(ids)}\n",
    "\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=n_splits,\n",
    "        shuffle=True,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    fold_specs = []\n",
    "    for fold_id, (train_idx, val_idx) in enumerate(skf.split(ids, y)):\n",
    "        fold_specs.append((fold_id, ids[train_idx], ids[val_idx]))\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(_run_fold)(\n",
    "            fold_id,\n",
    "            train_ids,\n",
    "            val_ids,\n",
    "            df,\n",
    "            C,\n",
    "            min_pos_repertoires,\n",
    "            min_log_odds,\n",
    "            use_vj,\n",
    "            penalty_cv,\n",
    "            class_weight,\n",
    "            l1_ratio_cv,\n",
    "            extra_clone_ids,\n",
    "        )\n",
    "        for fold_id, train_ids, val_ids in fold_specs\n",
    "    )\n",
    "\n",
    "    oof = np.zeros(len(ids), dtype=float)\n",
    "    fold_aucs = []\n",
    "    for fold_id, val_ids, val_pred, fold_auc, n_sel in results:\n",
    "        idxs = [id_to_idx[rid] for rid in val_ids]\n",
    "        oof[idxs] = val_pred\n",
    "        fold_aucs.append(fold_auc)\n",
    "\n",
    "    cv_auc = roc_auc_score(y, oof)\n",
    "    print(f\"[cv] overall auc={cv_auc:.4f}\")\n",
    "\n",
    "    all_stats_full, enriched_full = find_enriched_public_clones(\n",
    "        df,\n",
    "        min_pos_repertoires=min_pos_repertoires,\n",
    "        min_log_odds=min_log_odds,\n",
    "        use_vj=use_vj,\n",
    "        extra_clone_ids=extra_clone_ids,\n",
    "    )\n",
    "    selected_full = enriched_full[\"clone_id\"]\n",
    "\n",
    "    if len(selected_full) == 0:\n",
    "        print(\"[full] no clones selected; training intercept-only model\")\n",
    "        X_full = pd.DataFrame(\n",
    "            {\"bias\": np.ones(len(rep_label), dtype=np.float32)},\n",
    "            index=rep_label[\"ID\"].values,\n",
    "        )\n",
    "    else:\n",
    "        print(f\"[full] n_selected={len(selected_full)}\")\n",
    "        X_full = build_public_clone_presence_matrix(df, selected_full, use_vj=use_vj)\n",
    "\n",
    "    y_full = (\n",
    "        df[[\"ID\", \"label_positive\"]]\n",
    "        .drop_duplicates(\"ID\")\n",
    "        .set_index(\"ID\")[\"label_positive\"]\n",
    "        .astype(int)\n",
    "        .loc[X_full.index]\n",
    "    )\n",
    "\n",
    "    if penalty_final is None:\n",
    "        penalty_final = penalty_cv\n",
    "    if l1_ratio_final is None:\n",
    "        l1_ratio_final = l1_ratio_cv\n",
    "\n",
    "    final_clf = _make_logreg(\n",
    "        penalty=penalty_final,\n",
    "        C=C,\n",
    "        class_weight=class_weight,\n",
    "        l1_ratio=l1_ratio_final,\n",
    "    )\n",
    "    final_clf.fit(X_full.values, y_full.values)\n",
    "\n",
    "    return final_clf, cv_auc, oof, X_full, y_full, all_stats_full, enriched_full, fold_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f174a28-cebf-49aa-a26e-a935f8e16ddd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:57.057496Z",
     "iopub.status.busy": "2025-12-13T15:30:57.057325Z",
     "iopub.status.idle": "2025-12-13T15:30:57.063511Z",
     "shell.execute_reply": "2025-12-13T15:30:57.063052Z",
     "shell.execute_reply.started": "2025-12-13T15:30:57.057483Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def find_enriched_public_clones(\n",
    "    df,\n",
    "    min_pos_repertoires=3,\n",
    "    min_log_odds=1.0,\n",
    "    use_vj=True,\n",
    "    extra_clone_ids=None,\n",
    "):\n",
    "    df = df.copy()\n",
    "    if use_vj:\n",
    "        df[\"clone_id\"] = (\n",
    "            df[\"junction_aa\"].astype(\"string\")\n",
    "            + \"|\" + df[\"v_call\"].astype(\"string\")\n",
    "            + \"|\" + df[\"j_call\"].astype(\"string\")\n",
    "        )\n",
    "    else:\n",
    "        df[\"clone_id\"] = df[\"junction_aa\"].astype(\"string\")\n",
    "\n",
    "    rep_label = df[[\"ID\", \"label_positive\"]].drop_duplicates(\"ID\")\n",
    "    rep_label[\"label_positive\"] = rep_label[\"label_positive\"].astype(np.int8)\n",
    "\n",
    "    n_pos = int((rep_label[\"label_positive\"] == 1).sum())\n",
    "    n_neg = int((rep_label[\"label_positive\"] == 0).sum())\n",
    "\n",
    "    tmp = df[[\"clone_id\", \"ID\", \"label_positive\"]].drop_duplicates([\"clone_id\", \"ID\"])\n",
    "\n",
    "    ct = pd.crosstab(tmp[\"clone_id\"], tmp[\"label_positive\"])\n",
    "    ct = ct.reindex(columns=[0, 1], fill_value=0).astype(np.int32)\n",
    "    ct = ct.rename(columns={0: \"neg_reps\", 1: \"pos_reps\"})\n",
    "\n",
    "    alpha = 0.5\n",
    "    pos = ct[\"pos_reps\"].to_numpy()\n",
    "    neg = ct[\"neg_reps\"].to_numpy()\n",
    "\n",
    "    log_odds = np.log(\n",
    "        (pos + alpha) / (n_pos - pos + alpha)\n",
    "    ) - np.log(\n",
    "        (neg + alpha) / (n_neg - neg + alpha)\n",
    "    )\n",
    "\n",
    "    ct = ct.assign(log_odds=log_odds, clone_id=ct.index).reset_index(drop=True)\n",
    "\n",
    "    enriched = ct[\n",
    "        (ct[\"pos_reps\"] >= min_pos_repertoires) &\n",
    "        (ct[\"log_odds\"] >= min_log_odds)\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    if extra_clone_ids is not None:\n",
    "        extra_clone_ids = set(extra_clone_ids)\n",
    "        extra_mask = ct[\"clone_id\"].isin(extra_clone_ids)\n",
    "        extra_df = ct[extra_mask & ~ct[\"clone_id\"].isin(enriched[\"clone_id\"])]\n",
    "        if not extra_df.empty:\n",
    "            enriched = pd.concat([enriched, extra_df], ignore_index=True)\n",
    "\n",
    "    return ct, enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dab73274-17e2-4218-b65b-7f0c1525c039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:57.064117Z",
     "iopub.status.busy": "2025-12-13T15:30:57.063976Z",
     "iopub.status.idle": "2025-12-13T15:30:57.071647Z",
     "shell.execute_reply": "2025-12-13T15:30:57.071177Z",
     "shell.execute_reply.started": "2025-12-13T15:30:57.064106Z"
    }
   },
   "outputs": [],
   "source": [
    "def _run_fold(\n",
    "    fold_id,\n",
    "    train_ids,\n",
    "    val_ids,\n",
    "    df,\n",
    "    C,\n",
    "    min_pos_repertoires,\n",
    "    min_log_odds,\n",
    "    use_vj,\n",
    "    penalty_cv=\"l1\",\n",
    "    class_weight=None,\n",
    "    l1_ratio_cv=None,\n",
    "    extra_clone_ids=None,\n",
    "):\n",
    "    print(f\"[fold {fold_id+1}] start: n_train_ids={len(train_ids)}, n_val_ids={len(val_ids)}\")\n",
    "\n",
    "    df_train = df[df[\"ID\"].isin(train_ids)]\n",
    "    df_val = df[df[\"ID\"].isin(val_ids)]\n",
    "\n",
    "    # --- 1. Feature Selection ---\n",
    "    all_stats_tr, enriched_tr = find_enriched_public_clones(\n",
    "        df_train,\n",
    "        min_pos_repertoires=min_pos_repertoires,\n",
    "        min_log_odds=min_log_odds,\n",
    "        use_vj=use_vj,\n",
    "        extra_clone_ids=extra_clone_ids,\n",
    "    )\n",
    "    selected = enriched_tr[\"clone_id\"]\n",
    "    n_sel = len(selected)\n",
    "\n",
    "    # Handle case where NO clones were found\n",
    "    if n_sel == 0:\n",
    "        rep_label_val = (\n",
    "            df_val[[\"ID\", \"label_positive\"]]\n",
    "            .drop_duplicates(\"ID\")\n",
    "            .set_index(\"ID\")[\"label_positive\"]\n",
    "            .astype(int)\n",
    "        )\n",
    "        base_rate = rep_label_val.mean()\n",
    "        val_pred = np.full(len(rep_label_val), base_rate, dtype=float)\n",
    "        try:\n",
    "            fold_auc = roc_auc_score(rep_label_val.values, val_pred)\n",
    "        except ValueError:\n",
    "            fold_auc = np.nan\n",
    "        print(f\"[fold {fold_id+1}] auc={fold_auc}, n_selected={n_sel} (constant preds, no clones)\")\n",
    "        return fold_id, rep_label_val.index.to_numpy(), val_pred, fold_auc, n_sel\n",
    "\n",
    "    # --- 2. Build Matrices ---\n",
    "    X_train = build_public_clone_presence_matrix(df_train, selected, use_vj=use_vj)\n",
    "    X_val = build_public_clone_presence_matrix(df_val, selected, use_vj=use_vj)\n",
    "\n",
    "    # --- 3. CRITICAL FIX: Reindex to include subjects with 0 counts ---\n",
    "    # This brings back the Negative subjects who were dropped because \n",
    "    # they didn't have any of the \"enriched\" clones.\n",
    "    X_train = X_train.reindex(index=train_ids, fill_value=0)\n",
    "    X_val = X_val.reindex(index=val_ids, fill_value=0)\n",
    "\n",
    "    # --- 4. Align Targets ---\n",
    "    # Now y_train will correspond exactly to train_ids (including Negatives)\n",
    "    y_train = (\n",
    "        df[[\"ID\", \"label_positive\"]]\n",
    "        .drop_duplicates(\"ID\")\n",
    "        .set_index(\"ID\")[\"label_positive\"]\n",
    "        .astype(int)\n",
    "        .loc[X_train.index]\n",
    "    )\n",
    "    \n",
    "    y_val = (\n",
    "        df[[\"ID\", \"label_positive\"]]\n",
    "        .drop_duplicates(\"ID\")\n",
    "        .set_index(\"ID\")[\"label_positive\"]\n",
    "        .astype(int)\n",
    "        .loc[X_val.index]\n",
    "    )\n",
    "\n",
    "    # --- 5. Safety Checks ---\n",
    "    if y_train.nunique() < 2:\n",
    "        # This should theoretically not happen now, unless the fold SPLIT itself \n",
    "        # put only Positives in train (which StratifiedKFold prevents).\n",
    "        base_rate = y_train.mean()\n",
    "        val_pred = np.full(len(y_val), base_rate, dtype=float)\n",
    "        try:\n",
    "            fold_auc = roc_auc_score(y_val.values, val_pred)\n",
    "        except ValueError:\n",
    "            fold_auc = np.nan\n",
    "        print(\n",
    "            f\"[fold {fold_id+1}] single-class y_train (after reindex), using constant preds; \"\n",
    "            f\"auc={fold_auc}, n_selected={n_sel}\"\n",
    "        )\n",
    "        return fold_id, y_val.index.to_numpy(), val_pred, fold_auc, n_sel\n",
    "\n",
    "    # --- 6. Train & Predict ---\n",
    "    clf = _make_logreg(\n",
    "        penalty=penalty_cv,\n",
    "        C=C,\n",
    "        class_weight=class_weight,\n",
    "        l1_ratio=l1_ratio_cv,\n",
    "    )\n",
    "    \n",
    "    clf.fit(X_train.values, y_train.values)\n",
    "    val_pred = clf.predict_proba(X_val.values)[:, 1]\n",
    "    \n",
    "    try:\n",
    "        fold_auc = roc_auc_score(y_val.values, val_pred)\n",
    "    except ValueError:\n",
    "        fold_auc = np.nan\n",
    "\n",
    "    print(f\"[fold {fold_id+1}] auc={fold_auc:.4f}, n_selected={n_sel}\")\n",
    "    return fold_id, y_val.index.to_numpy(), val_pred, fold_auc, n_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a9794cd-c89e-46b3-875f-3c565ef080d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T15:30:57.072377Z",
     "iopub.status.busy": "2025-12-13T15:30:57.072238Z",
     "iopub.status.idle": "2025-12-13T18:42:22.595510Z",
     "shell.execute_reply": "2025-12-13T18:42:22.594821Z",
     "shell.execute_reply.started": "2025-12-13T15:30:57.072365Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|| 400/400 [00:05<00:00, 75.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Joblib Random Search for train_dataset_1 using 35 cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=35)]: Using backend LokyBackend with 35 concurrent workers.\n",
      "[Parallel(n_jobs=35)]: Done 130 tasks      | elapsed: 66.3min\n",
      "[Parallel(n_jobs=35)]: Done 400 out of 400 | elapsed: 186.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset_1 Best AUC: 0.5306\n",
      "Best Params: {'min_pos_repertoires': 2, 'min_log_odds': 2.0, 'C': 10.0, 'penalty': 'l1', 'class_weight': 'balanced', 'l1_ratio': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|| 400/400 [00:04<00:00, 81.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote results_05E_Pub_Clones/test_dataset_1_submission.tsv\n",
      "wrote results_05E_Pub_Clones/train_dataset_1_important_sequences.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. DEFINE FUNCTIONS (All in one place to ensure freshness)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def _make_logreg(penalty, C, class_weight, l1_ratio):\n",
    "    if penalty == \"elasticnet\":\n",
    "        if l1_ratio is None:\n",
    "            l1_ratio = 0.5\n",
    "        return LogisticRegression(\n",
    "            penalty=\"elasticnet\",\n",
    "            C=C,\n",
    "            solver=\"saga\",\n",
    "            max_iter=10000,\n",
    "            class_weight=class_weight,\n",
    "            l1_ratio=l1_ratio,\n",
    "        )\n",
    "    elif penalty in (\"l1\", \"l2\"):\n",
    "        return LogisticRegression(\n",
    "            penalty=penalty,\n",
    "            C=C,\n",
    "            solver=\"liblinear\",\n",
    "            max_iter=10000,\n",
    "            class_weight=class_weight,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"unsupported penalty: {penalty}\")\n",
    "\n",
    "def _run_fold(\n",
    "    fold_id,\n",
    "    train_ids,\n",
    "    val_ids,\n",
    "    df,\n",
    "    C,\n",
    "    min_pos_repertoires,\n",
    "    min_log_odds,\n",
    "    use_vj,\n",
    "    penalty_cv,\n",
    "    class_weight,\n",
    "    l1_ratio_cv,\n",
    "    extra_clone_ids\n",
    "):\n",
    "    # Filter data\n",
    "    df_train = df[df[\"ID\"].isin(train_ids)]\n",
    "    df_val = df[df[\"ID\"].isin(val_ids)]\n",
    "\n",
    "    # --- Feature Selection ---\n",
    "    all_stats_tr, enriched_tr = find_enriched_public_clones(\n",
    "        df_train,\n",
    "        min_pos_repertoires=min_pos_repertoires,\n",
    "        min_log_odds=min_log_odds,\n",
    "        use_vj=use_vj,\n",
    "        extra_clone_ids=extra_clone_ids,\n",
    "    )\n",
    "    selected = enriched_tr[\"clone_id\"]\n",
    "    n_sel = len(selected)\n",
    "\n",
    "    # --- Edge Case: No Features ---\n",
    "    if n_sel == 0:\n",
    "        rep_label_val = (\n",
    "            df_val[[\"ID\", \"label_positive\"]]\n",
    "            .drop_duplicates(\"ID\")\n",
    "            .set_index(\"ID\")[\"label_positive\"]\n",
    "            .astype(int)\n",
    "        )\n",
    "        base_rate = rep_label_val.mean()\n",
    "        val_pred = np.full(len(rep_label_val), base_rate, dtype=float)\n",
    "        try:\n",
    "            fold_auc = roc_auc_score(rep_label_val.values, val_pred)\n",
    "        except ValueError:\n",
    "            fold_auc = 0.5 \n",
    "        return fold_id, rep_label_val.index.to_numpy(), val_pred, fold_auc, n_sel\n",
    "\n",
    "    # --- Build Matrices ---\n",
    "    X_train = build_public_clone_presence_matrix(df_train, selected, use_vj=use_vj)\n",
    "    X_val = build_public_clone_presence_matrix(df_val, selected, use_vj=use_vj)\n",
    "\n",
    "    # --- CRITICAL FIX: Reindex to force inclusion of subjects with 0 clones ---\n",
    "    # This brings back the Negative subjects who were dropped because they have no clones.\n",
    "    # We fill their rows with 0.0.\n",
    "    X_train = X_train.reindex(index=train_ids, fill_value=0.0)\n",
    "    X_val = X_val.reindex(index=val_ids, fill_value=0.0)\n",
    "\n",
    "    # --- Align Targets ---\n",
    "    y_train = (\n",
    "        df[[\"ID\", \"label_positive\"]]\n",
    "        .drop_duplicates(\"ID\")\n",
    "        .set_index(\"ID\")[\"label_positive\"]\n",
    "        .astype(int)\n",
    "        .loc[X_train.index]\n",
    "    )\n",
    "    \n",
    "    y_val = (\n",
    "        df[[\"ID\", \"label_positive\"]]\n",
    "        .drop_duplicates(\"ID\")\n",
    "        .set_index(\"ID\")[\"label_positive\"]\n",
    "        .astype(int)\n",
    "        .loc[X_val.index]\n",
    "    )\n",
    "\n",
    "    # --- Safety Check: Ensure 2 classes ---\n",
    "    if y_train.nunique() < 2:\n",
    "        # If we still have only 1 class, return constant prediction (0.5 AUC)\n",
    "        return fold_id, y_val.index.to_numpy(), np.zeros(len(y_val)), 0.5, n_sel\n",
    "\n",
    "    # --- Train & Predict ---\n",
    "    clf = _make_logreg(\n",
    "        penalty=penalty_cv,\n",
    "        C=C,\n",
    "        class_weight=class_weight,\n",
    "        l1_ratio=l1_ratio_cv,\n",
    "    )\n",
    "    \n",
    "    clf.fit(X_train.values, y_train.values)\n",
    "    val_pred = clf.predict_proba(X_val.values)[:, 1]\n",
    "    \n",
    "    try:\n",
    "        fold_auc = roc_auc_score(y_val.values, val_pred)\n",
    "    except ValueError:\n",
    "        fold_auc = 0.5\n",
    "\n",
    "    return fold_id, y_val.index.to_numpy(), val_pred, fold_auc, n_sel\n",
    "\n",
    "def run_public_clone_l1_cv_noleak(\n",
    "    df,\n",
    "    min_pos_repertoires=3,\n",
    "    min_log_odds=1.0,\n",
    "    C=1.0,\n",
    "    n_splits=5,\n",
    "    random_state=0,\n",
    "    n_jobs=2,  # Default to 1 for inner loop\n",
    "    use_vj=True,\n",
    "    penalty_cv=\"l1\",\n",
    "    penalty_final=None,\n",
    "    class_weight=None,\n",
    "    l1_ratio_cv=None,\n",
    "    l1_ratio_final=None,\n",
    "    extra_clone_ids=None,\n",
    "):\n",
    "    rep_label = df[[\"ID\", \"label_positive\"]].drop_duplicates(\"ID\")\n",
    "    rep_label[\"label_positive\"] = rep_label[\"label_positive\"].astype(int)\n",
    "    ids = rep_label[\"ID\"].to_numpy()\n",
    "    y = rep_label[\"label_positive\"].to_numpy().astype(int)\n",
    "\n",
    "    # Basic check for enough data\n",
    "    counts = np.bincount(y, minlength=2)\n",
    "    if (counts > 0).sum() < 2:\n",
    "        return None, -1.0, None, None, None, None, None, []\n",
    "    \n",
    "    n_splits = min(n_splits, int(counts.min()))\n",
    "    if n_splits < 2:\n",
    "        return None, -1.0, None, None, None, None, None, []\n",
    "    id_to_idx = {rid: i for i, rid in enumerate(ids)}\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    fold_specs = []\n",
    "    for fold_id, (train_idx, val_idx) in enumerate(skf.split(ids, y)):\n",
    "        fold_specs.append((fold_id, ids[train_idx], ids[val_idx]))\n",
    "\n",
    "    # Run Folds\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(_run_fold)(\n",
    "            fold_id, train_ids, val_ids, df, C, min_pos_repertoires, min_log_odds, use_vj,\n",
    "            penalty_cv, class_weight, l1_ratio_cv, extra_clone_ids\n",
    "        )\n",
    "        for fold_id, train_ids, val_ids in fold_specs\n",
    "    )\n",
    "\n",
    "    oof = np.zeros(len(ids), dtype=float)\n",
    "    fold_aucs = []\n",
    "    for fold_id, val_ids, val_pred, fold_auc, n_sel in results:\n",
    "        idxs = [id_to_idx[rid] for rid in val_ids]\n",
    "        oof[idxs] = val_pred\n",
    "        fold_aucs.append(fold_auc)\n",
    "\n",
    "    cv_auc = roc_auc_score(y, oof)\n",
    "\n",
    "    # Final Model Training\n",
    "    all_stats_full, enriched_full = find_enriched_public_clones(\n",
    "        df, min_pos_repertoires=min_pos_repertoires, min_log_odds=min_log_odds, use_vj=use_vj, extra_clone_ids=extra_clone_ids\n",
    "    )\n",
    "    selected_full = enriched_full[\"clone_id\"]\n",
    "\n",
    "    if len(selected_full) == 0:\n",
    "        X_full = pd.DataFrame({\"bias\": np.ones(len(rep_label), dtype=np.float32)}, index=rep_label[\"ID\"].values)\n",
    "    else:\n",
    "        X_full = build_public_clone_presence_matrix(df, selected_full, use_vj=use_vj)\n",
    "        # CRITICAL: Reindex final model matrix too\n",
    "        X_full = X_full.reindex(index=ids, fill_value=0.0)\n",
    "\n",
    "    y_full = df[[\"ID\", \"label_positive\"]].drop_duplicates(\"ID\").set_index(\"ID\")[\"label_positive\"].astype(int).loc[X_full.index]\n",
    "\n",
    "    if penalty_final is None: penalty_final = penalty_cv\n",
    "    if l1_ratio_final is None: l1_ratio_final = l1_ratio_cv\n",
    "\n",
    "    final_clf = _make_logreg(penalty=penalty_final, C=C, class_weight=class_weight, l1_ratio=l1_ratio_final)\n",
    "    final_clf.fit(X_full.values, y_full.values)\n",
    "\n",
    "    return final_clf, cv_auc, oof, X_full, y_full, all_stats_full, enriched_full, fold_aucs\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. RUN SEARCH\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "log_file = \"training_auc_05E_log.tsv\"\n",
    "log_file = \"training_auc_05E_log.tsv\"\n",
    "\n",
    "\n",
    "pairs = [\n",
    "    ('train_datasets/train_datasets/train_dataset_1',\n",
    "     ['test_datasets/test_datasets/test_dataset_1'])\n",
    "]\n",
    "\n",
    "\n",
    "penalty_options     = [\"l1\", \"elasticnet\"]\n",
    "\n",
    "\n",
    "C_values = [10.0, 50.0, 80.0, 100.0]\n",
    "\n",
    "\n",
    "min_pos_values = [2]\n",
    "\n",
    "\n",
    "min_log_odds_values = [2.0,3.0, 4.0, 5.0]\n",
    "\n",
    "# High C values are excellent here. \n",
    "# They force the model to pay attention to the few rare signals it finds.\n",
    "C_values = [10.0, 50.0, 80.0, 100.0]\n",
    "\n",
    "# Keep strictly closer to 1.0 (Lasso) to zero out noise.\n",
    "l1_ratio_options = [0.95, 0.975, 1.0] \n",
    "\n",
    "# Keep balanced\n",
    "class_weight_options = [\"balanced\"]\n",
    "#tried N_TRIALS=100, 200,250,300\n",
    "\n",
    "N_TRIALS = 400\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 123\n",
    "\n",
    "N_FOLD_JOBS = 1        \n",
    "PARALLEL_JOBS = 35    \n",
    "\n",
    "\n",
    "submission_out_dir = \"results_05E_Pub_Clones\"\n",
    "important_out_dir = \"results_05E_Pub_Clones\"\n",
    "os.makedirs(submission_out_dir, exist_ok=True)\n",
    "os.makedirs(important_out_dir, exist_ok=True)\n",
    "\n",
    "for train_dir, test_dirs in pairs:\n",
    "    train_name = os.path.basename(train_dir)\n",
    "    imp_out_path = os.path.join(important_out_dir, f\"{train_name}_important_sequences.tsv\")\n",
    "    submission_paths = [os.path.join(submission_out_dir, f\"{os.path.basename(td)}_submission.tsv\") for td in test_dirs]\n",
    "\n",
    "    if os.path.exists(imp_out_path) and all(os.path.exists(p) for p in submission_paths):\n",
    "        print(f\"Skipping {train_name}: all outputs already exist.\")\n",
    "        continue\n",
    "\n",
    "    full_df = load_full_dataset(train_dir)\n",
    "\n",
    "    def run_random_trial(trial_idx):\n",
    "        min_pos = random.choice(min_pos_values)\n",
    "        min_lo = random.choice(min_log_odds_values)\n",
    "        C = random.choice(C_values)\n",
    "        penalty = random.choice(penalty_options)\n",
    "        class_weight = random.choice(class_weight_options)\n",
    "        l1_ratio = random.choice(l1_ratio_options) if penalty == \"elasticnet\" else None\n",
    "        \n",
    "        try:\n",
    "            # We call the CV function with n_jobs=1 because we are already parallelized here\n",
    "            _, cv_auc, _, _, _, _, _, _ = run_public_clone_l1_cv_noleak(\n",
    "                full_df,\n",
    "                min_pos_repertoires=min_pos,\n",
    "                min_log_odds=min_lo,\n",
    "                C=C,\n",
    "                n_splits=N_SPLITS,\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_jobs=1,        # FIXED: Inner loop sequential\n",
    "                use_vj=True,     # FIXED: Explicit True\n",
    "                penalty_cv=penalty,\n",
    "                penalty_final=penalty,\n",
    "                class_weight=class_weight,\n",
    "                l1_ratio_cv=l1_ratio,\n",
    "                l1_ratio_final=l1_ratio,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Catch errors so one bad trial doesn't kill the batch\n",
    "            # print(f\"Trial {trial_idx} failed: {e}\") \n",
    "            cv_auc = -1.0\n",
    "    \n",
    "        return {\n",
    "            \"trial_idx\": trial_idx, \"cv_auc\": cv_auc,\n",
    "            \"params\": {\n",
    "                \"min_pos_repertoires\": min_pos, \"min_log_odds\": min_lo, \"C\": C,\n",
    "                \"penalty\": penalty, \"class_weight\": class_weight, \"l1_ratio\": l1_ratio\n",
    "            }\n",
    "        }\n",
    "\n",
    "    print(f\"Starting Joblib Random Search for {train_name} using {PARALLEL_JOBS} cores...\")\n",
    "    \n",
    "    results = Parallel(n_jobs=PARALLEL_JOBS, verbose=1)(\n",
    "        delayed(run_random_trial)(i) for i in range(N_TRIALS)\n",
    "    )\n",
    "\n",
    "    valid_results = [r for r in results if r[\"cv_auc\"] >= 0]\n",
    "    if not valid_results:\n",
    "        print(f\"All trials failed for {train_name}.\")\n",
    "        continue\n",
    "\n",
    "    best_result = max(valid_results, key=lambda x: x[\"cv_auc\"])\n",
    "    best_params = best_result[\"params\"]\n",
    "    print(f\"{train_name} Best AUC: {best_result['cv_auc']:.4f}\")\n",
    "    print(f\"Best Params: {best_params}\")\n",
    "\n",
    "    # Retrain final model (can use parallel folds here since outer loop is done)\n",
    "    final_clf, cv_auc, oof_public, X_pub, y_pub, all_stats, enriched_public, fold_aucs = run_public_clone_l1_cv_noleak(\n",
    "        full_df,\n",
    "        min_pos_repertoires=best_params[\"min_pos_repertoires\"],\n",
    "        min_log_odds=best_params[\"min_log_odds\"],\n",
    "        C=best_params[\"C\"],\n",
    "        n_splits=N_SPLITS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=PARALLEL_JOBS, # Now we can use parallel cores for the final fit\n",
    "        use_vj=True,\n",
    "        penalty_cv=best_params[\"penalty\"],\n",
    "        penalty_final=best_params[\"penalty\"],\n",
    "        class_weight=best_params[\"class_weight\"],\n",
    "        l1_ratio_cv=best_params[\"l1_ratio\"],\n",
    "        l1_ratio_final=best_params[\"l1_ratio\"],\n",
    "    )\n",
    "\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"{train_name}\\t{best_params['min_pos_repertoires']}\\t{best_params['min_log_odds']}\\t{best_params['C']}\\t{best_params['penalty']}\\t{best_params['class_weight']}\\t{best_params['l1_ratio']}\\t{cv_auc}\\n\")\n",
    "\n",
    "    # Generate Predictions and Important Sequences\n",
    "    for test_dir in test_dirs:\n",
    "        test_name = os.path.basename(test_dir)\n",
    "        out_path = os.path.join(submission_out_dir, f\"{test_name}_submission.tsv\")\n",
    "        if os.path.exists(out_path): continue\n",
    "\n",
    "        df_test = load_full_dataset(test_dir)\n",
    "        pred_test_public, X_test_public = predict_public_clone_model(df_test, final_clf=final_clf, enriched_public=enriched_public, use_vj=True)\n",
    "\n",
    "        if \"label_positive\" in df_test.columns:\n",
    "            y_test = df_test[[\"ID\", \"label_positive\"]].drop_duplicates(\"ID\").set_index(\"ID\")[\"label_positive\"].astype(int).loc[pred_test_public[\"ID\"]].to_numpy()\n",
    "            try:\n",
    "                test_auc = roc_auc_score(y_test, pred_test_public[\"pred_public\"])\n",
    "            except: test_auc = 0.5\n",
    "            print(f\"{test_name} test auc: {test_auc:.4f}\")\n",
    "            with open(log_file, \"a\") as f: f.write(f\"{train_name}\\t{test_name}\\ttest_auc_public\\t{test_auc}\\n\")\n",
    "\n",
    "        preds_to_submission(pred_test_public, dataset_name=test_name).to_csv(out_path, sep=\"\\t\", index=False)\n",
    "        print(f\"wrote {out_path}\")\n",
    "\n",
    "    if not os.path.exists(imp_out_path):\n",
    "        n_top = 50000\n",
    "        all_stats_sorted = all_stats.sort_values(\"log_odds\", ascending=False)\n",
    "        enriched_ids = set(enriched_public[\"clone_id\"])\n",
    "        extra_stats = all_stats_sorted[~all_stats_sorted[\"clone_id\"].isin(enriched_ids)].head(max(0, n_top - len(enriched_ids)))\n",
    "        top_stats = pd.concat([enriched_public, extra_stats], ignore_index=True).drop_duplicates(\"clone_id\")\n",
    "        stats_to_seq_table(top_stats, dataset_name=train_name, start_rank=1).to_csv(imp_out_path, sep=\"\\t\", index=False)\n",
    "        print(f\"wrote {imp_out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "639c4d52-1864-4d0d-b50e-26480c964859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T18:42:22.596297Z",
     "iopub.status.busy": "2025-12-13T18:42:22.596124Z",
     "iopub.status.idle": "2025-12-13T22:01:41.036580Z",
     "shell.execute_reply": "2025-12-13T22:01:41.035929Z",
     "shell.execute_reply.started": "2025-12-13T18:42:22.596281Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|| 400/400 [00:04<00:00, 82.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Joblib Random Search for train_dataset_3 using 35 cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=35)]: Using backend LokyBackend with 35 concurrent workers.\n",
      "[Parallel(n_jobs=35)]: Done 130 tasks      | elapsed: 69.1min\n",
      "[Parallel(n_jobs=35)]: Done 400 out of 400 | elapsed: 194.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset_3 Best AUC: 0.7920\n",
      "Best Params: {'min_pos_repertoires': 6, 'min_log_odds': 1.75, 'C': 6.0, 'penalty': 'elasticnet', 'class_weight': 'balanced', 'l1_ratio': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|| 400/400 [00:04<00:00, 89.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote results_05E_Pub_Clones/test_dataset_3_submission.tsv\n",
      "wrote results_05E_Pub_Clones/train_dataset_3_important_sequences.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from joblib import Parallel, delayed  \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "log_file = \"training_auc_05E_log.tsv\"\n",
    "\n",
    "\n",
    "pairs = [\n",
    "    ('train_datasets/train_datasets/train_dataset_3',\n",
    "     ['test_datasets/test_datasets/test_dataset_3'])\n",
    "]\n",
    "\n",
    "\n",
    "min_pos_values      = [ 6]\n",
    "min_log_odds_values = [1.6, 1.65, 1.7,1.75]\n",
    "C_values            = [4.0,4.5, 5.0,5.5,6.0]\n",
    "penalty_options     = [ \"elasticnet\"]\n",
    "class_weight_options = [ None, \"balanced\"]\n",
    "l1_ratio_options    = [0.75, 0.9, 0.8, 0.85]\n",
    "\n",
    "#tried N_TRIALS=100, 200,250,300\n",
    "\n",
    "N_TRIALS = 400\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 123\n",
    "\n",
    "N_FOLD_JOBS = 1        \n",
    "PARALLEL_JOBS = 35    \n",
    "\n",
    "\n",
    "submission_out_dir = \"results_05E_Pub_Clones\"\n",
    "important_out_dir = \"results_05E_Pub_Clones\"\n",
    "os.makedirs(submission_out_dir, exist_ok=True)\n",
    "os.makedirs(important_out_dir, exist_ok=True)\n",
    "\n",
    "for train_dir, test_dirs in pairs:\n",
    "    train_name = os.path.basename(train_dir)\n",
    "    imp_out_path = os.path.join(important_out_dir, f\"{train_name}_important_sequences.tsv\")\n",
    "    submission_paths = [os.path.join(submission_out_dir, f\"{os.path.basename(td)}_submission.tsv\") for td in test_dirs]\n",
    "\n",
    "    if os.path.exists(imp_out_path) and all(os.path.exists(p) for p in submission_paths):\n",
    "        print(f\"Skipping {train_name}: all outputs already exist.\")\n",
    "        continue\n",
    "\n",
    "    full_df = load_full_dataset(train_dir)\n",
    "\n",
    "    def run_random_trial(trial_idx):\n",
    "        min_pos = random.choice(min_pos_values)\n",
    "        min_lo = random.choice(min_log_odds_values)\n",
    "        C = random.choice(C_values)\n",
    "        penalty = random.choice(penalty_options)\n",
    "        class_weight = random.choice(class_weight_options)\n",
    "        l1_ratio = random.choice(l1_ratio_options) if penalty == \"elasticnet\" else None\n",
    "        \n",
    "        try:\n",
    "            # We call the CV function with n_jobs=1 because we are already parallelized here\n",
    "            _, cv_auc, _, _, _, _, _, _ = run_public_clone_l1_cv_noleak(\n",
    "                full_df,\n",
    "                min_pos_repertoires=min_pos,\n",
    "                min_log_odds=min_lo,\n",
    "                C=C,\n",
    "                n_splits=N_SPLITS,\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_jobs=1,        # FIXED: Inner loop sequential\n",
    "                use_vj=True,     # FIXED: Explicit True\n",
    "                penalty_cv=penalty,\n",
    "                penalty_final=penalty,\n",
    "                class_weight=class_weight,\n",
    "                l1_ratio_cv=l1_ratio,\n",
    "                l1_ratio_final=l1_ratio,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Catch errors so one bad trial doesn't kill the batch\n",
    "            # print(f\"Trial {trial_idx} failed: {e}\") \n",
    "            cv_auc = -1.0\n",
    "    \n",
    "        return {\n",
    "            \"trial_idx\": trial_idx, \"cv_auc\": cv_auc,\n",
    "            \"params\": {\n",
    "                \"min_pos_repertoires\": min_pos, \"min_log_odds\": min_lo, \"C\": C,\n",
    "                \"penalty\": penalty, \"class_weight\": class_weight, \"l1_ratio\": l1_ratio\n",
    "            }\n",
    "        }\n",
    "\n",
    "    print(f\"Starting Joblib Random Search for {train_name} using {PARALLEL_JOBS} cores...\")\n",
    "    \n",
    "    results = Parallel(n_jobs=PARALLEL_JOBS, verbose=1)(\n",
    "        delayed(run_random_trial)(i) for i in range(N_TRIALS)\n",
    "    )\n",
    "\n",
    "    valid_results = [r for r in results if r[\"cv_auc\"] >= 0]\n",
    "    if not valid_results:\n",
    "        print(f\"All trials failed for {train_name}.\")\n",
    "        continue\n",
    "\n",
    "    best_result = max(valid_results, key=lambda x: x[\"cv_auc\"])\n",
    "    best_params = best_result[\"params\"]\n",
    "    print(f\"{train_name} Best AUC: {best_result['cv_auc']:.4f}\")\n",
    "    print(f\"Best Params: {best_params}\")\n",
    "\n",
    "    # Retrain final model (can use parallel folds here since outer loop is done)\n",
    "    final_clf, cv_auc, oof_public, X_pub, y_pub, all_stats, enriched_public, fold_aucs = run_public_clone_l1_cv_noleak(\n",
    "        full_df,\n",
    "        min_pos_repertoires=best_params[\"min_pos_repertoires\"],\n",
    "        min_log_odds=best_params[\"min_log_odds\"],\n",
    "        C=best_params[\"C\"],\n",
    "        n_splits=N_SPLITS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=PARALLEL_JOBS, # Now we can use parallel cores for the final fit\n",
    "        use_vj=True,\n",
    "        penalty_cv=best_params[\"penalty\"],\n",
    "        penalty_final=best_params[\"penalty\"],\n",
    "        class_weight=best_params[\"class_weight\"],\n",
    "        l1_ratio_cv=best_params[\"l1_ratio\"],\n",
    "        l1_ratio_final=best_params[\"l1_ratio\"],\n",
    "    )\n",
    "\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"{train_name}\\t{best_params['min_pos_repertoires']}\\t{best_params['min_log_odds']}\\t{best_params['C']}\\t{best_params['penalty']}\\t{best_params['class_weight']}\\t{best_params['l1_ratio']}\\t{cv_auc}\\n\")\n",
    "\n",
    "    # Generate Predictions and Important Sequences\n",
    "    for test_dir in test_dirs:\n",
    "        test_name = os.path.basename(test_dir)\n",
    "        out_path = os.path.join(submission_out_dir, f\"{test_name}_submission.tsv\")\n",
    "        if os.path.exists(out_path): continue\n",
    "\n",
    "        df_test = load_full_dataset(test_dir)\n",
    "        pred_test_public, X_test_public = predict_public_clone_model(df_test, final_clf=final_clf, enriched_public=enriched_public, use_vj=True)\n",
    "\n",
    "        if \"label_positive\" in df_test.columns:\n",
    "            y_test = df_test[[\"ID\", \"label_positive\"]].drop_duplicates(\"ID\").set_index(\"ID\")[\"label_positive\"].astype(int).loc[pred_test_public[\"ID\"]].to_numpy()\n",
    "            try:\n",
    "                test_auc = roc_auc_score(y_test, pred_test_public[\"pred_public\"])\n",
    "            except: test_auc = 0.5\n",
    "            print(f\"{test_name} test auc: {test_auc:.4f}\")\n",
    "            with open(log_file, \"a\") as f: f.write(f\"{train_name}\\t{test_name}\\ttest_auc_public\\t{test_auc}\\n\")\n",
    "\n",
    "        preds_to_submission(pred_test_public, dataset_name=test_name).to_csv(out_path, sep=\"\\t\", index=False)\n",
    "        print(f\"wrote {out_path}\")\n",
    "\n",
    "    if not os.path.exists(imp_out_path):\n",
    "        n_top = 50000\n",
    "        all_stats_sorted = all_stats.sort_values(\"log_odds\", ascending=False)\n",
    "        enriched_ids = set(enriched_public[\"clone_id\"])\n",
    "        extra_stats = all_stats_sorted[~all_stats_sorted[\"clone_id\"].isin(enriched_ids)].head(max(0, n_top - len(enriched_ids)))\n",
    "        top_stats = pd.concat([enriched_public, extra_stats], ignore_index=True).drop_duplicates(\"clone_id\")\n",
    "        stats_to_seq_table(top_stats, dataset_name=train_name, start_rank=1).to_csv(imp_out_path, sep=\"\\t\", index=False)\n",
    "        print(f\"wrote {imp_out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a801b31-a459-427f-bb13-8b5b22d11c72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T22:01:41.037376Z",
     "iopub.status.busy": "2025-12-13T22:01:41.037218Z",
     "iopub.status.idle": "2025-12-14T01:24:50.546050Z",
     "shell.execute_reply": "2025-12-14T01:24:50.545303Z",
     "shell.execute_reply.started": "2025-12-13T22:01:41.037360Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|| 400/400 [00:04<00:00, 87.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Joblib Random Search for train_dataset_6 using 35 cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=35)]: Using backend LokyBackend with 35 concurrent workers.\n",
      "[Parallel(n_jobs=35)]: Done 130 tasks      | elapsed: 70.6min\n",
      "[Parallel(n_jobs=35)]: Done 400 out of 400 | elapsed: 197.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset_6 Best AUC: 1.0000\n",
      "Best Params: {'min_pos_repertoires': 7, 'min_log_odds': 0.9, 'C': 5.0, 'penalty': 'elasticnet', 'class_weight': None, 'l1_ratio': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|| 400/400 [00:04<00:00, 88.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote results_05E_Pub_Clones/test_dataset_6_submission.tsv\n",
      "wrote results_05E_Pub_Clones/train_dataset_6_important_sequences.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from joblib import Parallel, delayed  \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "log_file = \"training_auc_05E_log.tsv\"\n",
    "\n",
    "\n",
    "pairs = [\n",
    "    ('train_datasets/train_datasets/train_dataset_6',\n",
    "     ['test_datasets/test_datasets/test_dataset_6'])\n",
    "]\n",
    "\n",
    "\n",
    "min_pos_values      = [5, 6, 7]\n",
    "min_log_odds_values = [0.9, 1.0, 1.25, 1.5, 1.75]\n",
    "C_values            = [0.75, 1.0, 2.0, 3.0, 5.0]\n",
    "penalty_options     = [\"l1\", \"elasticnet\"]\n",
    "class_weight_options = [None, \"balanced\"]\n",
    "l1_ratio_options    = [0.15, 0.2, 0.25, 0.5, 0.75, 0.8, 1.0]\n",
    "\n",
    "#tried N_TRIALS=100, 200,250,300\n",
    "\n",
    "N_TRIALS = 400\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 123\n",
    "\n",
    "N_FOLD_JOBS = 1        \n",
    "PARALLEL_JOBS = 35    \n",
    "\n",
    "\n",
    "submission_out_dir = \"results_05E_Pub_Clones\"\n",
    "important_out_dir = \"results_05E_Pub_Clones\"\n",
    "os.makedirs(submission_out_dir, exist_ok=True)\n",
    "os.makedirs(important_out_dir, exist_ok=True)\n",
    "\n",
    "for train_dir, test_dirs in pairs:\n",
    "    train_name = os.path.basename(train_dir)\n",
    "    imp_out_path = os.path.join(important_out_dir, f\"{train_name}_important_sequences.tsv\")\n",
    "    submission_paths = [os.path.join(submission_out_dir, f\"{os.path.basename(td)}_submission.tsv\") for td in test_dirs]\n",
    "\n",
    "    if os.path.exists(imp_out_path) and all(os.path.exists(p) for p in submission_paths):\n",
    "        print(f\"Skipping {train_name}: all outputs already exist.\")\n",
    "        continue\n",
    "\n",
    "    full_df = load_full_dataset(train_dir)\n",
    "\n",
    "    def run_random_trial(trial_idx):\n",
    "        min_pos = random.choice(min_pos_values)\n",
    "        min_lo = random.choice(min_log_odds_values)\n",
    "        C = random.choice(C_values)\n",
    "        penalty = random.choice(penalty_options)\n",
    "        class_weight = random.choice(class_weight_options)\n",
    "        l1_ratio = random.choice(l1_ratio_options) if penalty == \"elasticnet\" else None\n",
    "        \n",
    "        try:\n",
    "            # We call the CV function with n_jobs=1 because we are already parallelized here\n",
    "            _, cv_auc, _, _, _, _, _, _ = run_public_clone_l1_cv_noleak(\n",
    "                full_df,\n",
    "                min_pos_repertoires=min_pos,\n",
    "                min_log_odds=min_lo,\n",
    "                C=C,\n",
    "                n_splits=N_SPLITS,\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_jobs=1,        # FIXED: Inner loop sequential\n",
    "                use_vj=True,     # FIXED: Explicit True\n",
    "                penalty_cv=penalty,\n",
    "                penalty_final=penalty,\n",
    "                class_weight=class_weight,\n",
    "                l1_ratio_cv=l1_ratio,\n",
    "                l1_ratio_final=l1_ratio,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Catch errors so one bad trial doesn't kill the batch\n",
    "            # print(f\"Trial {trial_idx} failed: {e}\") \n",
    "            cv_auc = -1.0\n",
    "    \n",
    "        return {\n",
    "            \"trial_idx\": trial_idx, \"cv_auc\": cv_auc,\n",
    "            \"params\": {\n",
    "                \"min_pos_repertoires\": min_pos, \"min_log_odds\": min_lo, \"C\": C,\n",
    "                \"penalty\": penalty, \"class_weight\": class_weight, \"l1_ratio\": l1_ratio\n",
    "            }\n",
    "        }\n",
    "\n",
    "    print(f\"Starting Joblib Random Search for {train_name} using {PARALLEL_JOBS} cores...\")\n",
    "    \n",
    "    results = Parallel(n_jobs=PARALLEL_JOBS, verbose=1)(\n",
    "        delayed(run_random_trial)(i) for i in range(N_TRIALS)\n",
    "    )\n",
    "\n",
    "    valid_results = [r for r in results if r[\"cv_auc\"] >= 0]\n",
    "    if not valid_results:\n",
    "        print(f\"All trials failed for {train_name}.\")\n",
    "        continue\n",
    "\n",
    "    best_result = max(valid_results, key=lambda x: x[\"cv_auc\"])\n",
    "    best_params = best_result[\"params\"]\n",
    "    print(f\"{train_name} Best AUC: {best_result['cv_auc']:.4f}\")\n",
    "    print(f\"Best Params: {best_params}\")\n",
    "\n",
    "    # Retrain final model (can use parallel folds here since outer loop is done)\n",
    "    final_clf, cv_auc, oof_public, X_pub, y_pub, all_stats, enriched_public, fold_aucs = run_public_clone_l1_cv_noleak(\n",
    "        full_df,\n",
    "        min_pos_repertoires=best_params[\"min_pos_repertoires\"],\n",
    "        min_log_odds=best_params[\"min_log_odds\"],\n",
    "        C=best_params[\"C\"],\n",
    "        n_splits=N_SPLITS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=PARALLEL_JOBS, # Now we can use parallel cores for the final fit\n",
    "        use_vj=True,\n",
    "        penalty_cv=best_params[\"penalty\"],\n",
    "        penalty_final=best_params[\"penalty\"],\n",
    "        class_weight=best_params[\"class_weight\"],\n",
    "        l1_ratio_cv=best_params[\"l1_ratio\"],\n",
    "        l1_ratio_final=best_params[\"l1_ratio\"],\n",
    "    )\n",
    "\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"{train_name}\\t{best_params['min_pos_repertoires']}\\t{best_params['min_log_odds']}\\t{best_params['C']}\\t{best_params['penalty']}\\t{best_params['class_weight']}\\t{best_params['l1_ratio']}\\t{cv_auc}\\n\")\n",
    "\n",
    "    # Generate Predictions and Important Sequences\n",
    "    for test_dir in test_dirs:\n",
    "        test_name = os.path.basename(test_dir)\n",
    "        out_path = os.path.join(submission_out_dir, f\"{test_name}_submission.tsv\")\n",
    "        if os.path.exists(out_path): continue\n",
    "\n",
    "        df_test = load_full_dataset(test_dir)\n",
    "        pred_test_public, X_test_public = predict_public_clone_model(df_test, final_clf=final_clf, enriched_public=enriched_public, use_vj=True)\n",
    "\n",
    "        if \"label_positive\" in df_test.columns:\n",
    "            y_test = df_test[[\"ID\", \"label_positive\"]].drop_duplicates(\"ID\").set_index(\"ID\")[\"label_positive\"].astype(int).loc[pred_test_public[\"ID\"]].to_numpy()\n",
    "            try:\n",
    "                test_auc = roc_auc_score(y_test, pred_test_public[\"pred_public\"])\n",
    "            except: test_auc = 0.5\n",
    "            print(f\"{test_name} test auc: {test_auc:.4f}\")\n",
    "            with open(log_file, \"a\") as f: f.write(f\"{train_name}\\t{test_name}\\ttest_auc_public\\t{test_auc}\\n\")\n",
    "\n",
    "        preds_to_submission(pred_test_public, dataset_name=test_name).to_csv(out_path, sep=\"\\t\", index=False)\n",
    "        print(f\"wrote {out_path}\")\n",
    "\n",
    "    if not os.path.exists(imp_out_path):\n",
    "        n_top = 50000\n",
    "        all_stats_sorted = all_stats.sort_values(\"log_odds\", ascending=False)\n",
    "        enriched_ids = set(enriched_public[\"clone_id\"])\n",
    "        extra_stats = all_stats_sorted[~all_stats_sorted[\"clone_id\"].isin(enriched_ids)].head(max(0, n_top - len(enriched_ids)))\n",
    "        top_stats = pd.concat([enriched_public, extra_stats], ignore_index=True).drop_duplicates(\"clone_id\")\n",
    "        stats_to_seq_table(top_stats, dataset_name=train_name, start_rank=1).to_csv(imp_out_path, sep=\"\\t\", index=False)\n",
    "        print(f\"wrote {imp_out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f8025ee-0cac-4128-b520-134346033ce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T01:24:50.546885Z",
     "iopub.status.busy": "2025-12-14T01:24:50.546710Z",
     "iopub.status.idle": "2025-12-14T01:24:50.748818Z",
     "shell.execute_reply": "2025-12-14T01:24:50.742498Z",
     "shell.execute_reply.started": "2025-12-14T01:24:50.546869Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mx\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e1d0c-e26c-4eb7-97fd-7e3e57879d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42a72cb-e1a2-46f2-ad0d-dda6816725b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb731977-197a-4e04-98ef-3c70a78d4443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_BRI_Figures",
   "language": "python",
   "name": "python_bri_figures"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
